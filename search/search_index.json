{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#kano-utilities-for-your-computer-vision-projects","title":"\ud83e\udd8c Kano - Utilities for your Computer Vision Projects","text":"<p>Kano is a Python package providing utility functions for Computer Vision tasks. Its primary focus is simplifying lengthy functions, allowing developers to concentrate more on the main processes.</p>"},{"location":"#installation","title":"\ud83d\udce5 Installation","text":"<p>The latest released version is available on PyPI. You can install it by running the following command in your terminal:</p> <pre><code>pip install kano-cv\n</code></pre>"},{"location":"#usage","title":"\ud83d\ude80 Usage","text":"<p>Kano currently provides utilities for these groups:</p> <ul> <li>Common tasks:<ul> <li>Images Processing</li> <li>Videos Processing</li> <li>Files/Folders Manipulating</li> </ul> </li> <li>Computer vision tasks:<ul> <li>YOLO-formatted Dataset</li> <li>Object Detection</li> <li>Pose Estimation (In progress)</li> <li>Object Segmentation (In progress)</li> </ul> </li> <li>Real-time camera simulation<ul> <li>FPS, Resouces Profiling</li> <li>Real-time Camera Source Reader</li> <li>Real-time Fake Detection</li> </ul> </li> </ul>"},{"location":"common/","title":"Common Utilities","text":"<p>When working on computer vision tasks, developers often find themselves spending a considerable amount of time writing code for debugging or comparisons. Tasks such as displaying an image, downloading an image with a specific size, combining images or videos, extracting frames from videos, or displaying a folder tree of working directories can be time-consuming.</p> <p>Kano is a utilities library designed to simplify these tasks with just a few lines of code. It offers functions to handle common tasks, which can be categorized into image tasks, video tasks, and file tasks. Here are some examples:</p> <p>Test demo with Google Colab here: </p>"},{"location":"common/#image-tasks","title":"Image tasks","text":""},{"location":"common/#download-images-from-urls-and-show","title":"Download images from urls and show","text":"<p>The <code>show_image</code> code is compatible when running with both .py and .ipynb files.</p> <pre><code>from kano.image import download_image, show_image\n\n\nimage = download_image(\"https://avatars.githubusercontent.com/u/77763935?v=4\", \"image.jpg\")\n\n# using numpy array\nshow_image(image)\n\n# using file path\nshow_image(\"image.jpg\")\n</code></pre> <p>Result:</p> <p></p>"},{"location":"common/#download-image-with-desired-size","title":"Download image with desired size","text":"<pre><code>from kano.image import get_random_image\n\n\ndesired_image = get_random_image(width=400, height=300, save_path=\"random_image.jpg\")\n\n# using numpy array\nshow_image(desired_image)\n\n# using file path\nshow_image(\"random_image.jpg\")\n</code></pre> <p>Result:</p> <p></p>"},{"location":"common/#combine-images","title":"Combine images","text":"<p>The input images must be numpy arrays.</p> <pre><code>from kano.image import concatenate_images\n\n\nimage_list = [\n    [image, desired_image],\n    [desired_image]\n]\n\nconcatenated_image = concatenate_images(image_list)\nshow_image(concatenated_image)\n</code></pre> <p>Result:</p> <p></p>"},{"location":"common/#video-tasks","title":"Video tasks","text":""},{"location":"common/#extract-frames-from-a-video","title":"Extract frames from a video","text":"<p>Extract frames with a <code>seconds_interval</code> between each pair of consecutive frames, placed one after the other</p> <pre><code>from kano.video_utils import extract_frames\n\n\nextract_frames(\"video_1.mp4\", \"target_folder\", seconds_interval=1)\n</code></pre>"},{"location":"common/#combine-videos","title":"Combine videos","text":"<pre><code>from kano.video_utils import concatenate_videos\n\nvideo_paths = [\n    [\"video_1.mp4\", \"video_2.mp4\"],\n    [\"video_3.mp4\"]\n]\n\ntitles = [\n    [\"Video 1\", \"Video 2\"],\n    [\"Video 3\"],\n]\n\noutput_video_path = \"output_video.mp4\"\n\nconcatenate_videos(video_paths, titles, output_video_path)\n</code></pre> <p>A frame of concatenated video:</p> <p></p>"},{"location":"common/#file-tasks","title":"File tasks","text":""},{"location":"common/#list-files-folders-from-a-path","title":"List files, folders from a path","text":"<pre><code>from kano.file_utils import list_files, list_folders\n\n\nprint(\"List files paths :\", list_files(\"target_folder\"))\nprint(\"List folders paths: \", list_folders(\"/content\"))\n</code></pre> <p>Result:</p> <pre><code>List files paths : ['/content/target_folder/frame_000.jpg', '/content/target_folder/frame_030.jpg', '/content/target_folder/frame_060.jpg', '/content/target_folder/frame_090.jpg', '/content/target_folder/frame_120.jpg']\nList folders paths:  ['/content/.config', '/content/output_video_frames', '/content/sample_data', '/content/target_folder']\n</code></pre>"},{"location":"common/#print-the-folder-tree","title":"Print the folder tree","text":"<pre><code>from kano.file_utils import print_foldertree\n\n\nprint_foldertree(\"/content\", max_level=1, verbose=True)\n</code></pre> <p>Result:</p> <pre><code>/content (6 files + 4 folders)\n|\n|-- image.jpg (32.70 KB)\n|-- output_video.mp4 (32.41 KB)\n|-- random_image.jpg (19.67 KB)\n|-- video_1.mp4 (67.22 KB)\n|-- video_2.mp4 (261.71 KB)\n|-- video_3.mp4 (265.52 KB)\n|\n|-- .config (7 files + 2 folders)\n|\n|-- output_video_frames (5 files + 0 folders)\n|\n|-- sample_data (6 files + 0 folders)\n|\n|-- target_folder (5 files + 0 folders)\n</code></pre>"},{"location":"common/#create-remove-a-folder","title":"Create, remove a folder","text":"<p>Create a folder with its parent folders and remove a folder with its children items</p> <pre><code>from kano.file_utils import create_folder, remove_folder\n\n\n\ncreate_folder(\"new_folder\")\nprint_foldertree(\"/content\")\n\nprint(\"\\n\")\n\nremove_folder(\"new_folder\")\nprint_foldertree(\"/content\")\n</code></pre> <p>Result:</p> <pre><code>/content (6 files + 5 folders)\n|\n|-- image.jpg (32.70 KB)\n|-- output_video.mp4 (32.41 KB)\n|-- random_image.jpg (19.67 KB)\n|-- video_1.mp4 (67.22 KB)\n|-- video_2.mp4 (261.71 KB)\n|-- video_3.mp4 (265.52 KB)\n|\n|-- .config (7 files + 2 folders)\n|\n|-- new_folder (0 files + 0 folders)\n|\n|-- output_video_frames (5 files + 0 folders)\n|\n|-- sample_data (6 files + 0 folders)\n|\n|-- target_folder (5 files + 0 folders)\n\n\nFolder 'new_folder' and its contents removed successfully.\n/content (6 files + 4 folders)\n|\n|-- image.jpg (32.70 KB)\n|-- output_video.mp4 (32.41 KB)\n|-- random_image.jpg (19.67 KB)\n|-- video_1.mp4 (67.22 KB)\n|-- video_2.mp4 (261.71 KB)\n|-- video_3.mp4 (265.52 KB)\n|\n|-- .config (7 files + 2 folders)\n|\n|-- output_video_frames (5 files + 0 folders)\n|\n|-- sample_data (6 files + 0 folders)\n|\n|-- target_folder (5 files + 0 folders)\n</code></pre>"},{"location":"common/file_utils/","title":"File utilities","text":"<p>Kano provides some file-related functions:</p> <ul> <li><code>list_files</code>: get a list of files paths inside a folder.</li> <li><code>list_folders</code>: get a list of folders paths inside a folder.</li> <li><code>print_foldertree</code>: print foldertree of a folder and additional information.</li> <li><code>zip_paths</code>: zip a list of files and folders.</li> <li><code>create_folder</code>: create a folder and its parent folders if they don't exist.</li> <li><code>remove_folder</code>: remove a folder and its contents.</li> <li><code>print_package_versions</code>: print packages listed in requirements file and their version in the current environment.</li> </ul>"},{"location":"common/file_utils/#kano.file_utils.list_files","title":"<code>kano.file_utils.list_files(folder_path, return_absolute_paths=True)</code>","text":"<p>List files in a folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>Path to the folder.</p> required <code>return_absolute_paths</code> <code>bool</code> <p>Whether to return absolute paths or relative paths.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>sorted_files_paths</code> <code>list</code> <p>A list of file paths.</p> Source code in <code>kano\\file_utils.py</code> <pre><code>def list_files(folder_path, return_absolute_paths=True):\n    \"\"\"\n    List files in a folder.\n\n    Args:\n        folder_path (str): Path to the folder.\n        return_absolute_paths (bool): Whether to return absolute paths or relative paths.\n\n    Returns:\n        sorted_files_paths (list): A list of file paths.\n    \"\"\"\n    folder_path = Path(folder_path)\n    items = list(folder_path.iterdir())\n\n    files = [item.resolve() for item in items if item.is_file()]\n    sorted_files = sorted(files)\n\n    if not return_absolute_paths:\n        sorted_files = [file.relative_to(folder_path) for file in sorted_files]\n\n    sorted_files_paths = [str(file.as_posix()) for file in sorted_files]\n\n    return sorted_files_paths\n</code></pre>"},{"location":"common/file_utils/#kano.file_utils.list_folders","title":"<code>kano.file_utils.list_folders(folder_path, return_absolute_paths=True)</code>","text":"<p>List folders in a folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>Path to the folder.</p> required <code>return_absolute_paths</code> <code>bool</code> <p>Whether to return absolute paths or relative paths.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>sorted_folders_paths</code> <code>list</code> <p>A list of folder paths.</p> Source code in <code>kano\\file_utils.py</code> <pre><code>def list_folders(folder_path, return_absolute_paths=True):\n    \"\"\"\n    List folders in a folder.\n\n    Args:\n        folder_path (str): Path to the folder.\n        return_absolute_paths (bool): Whether to return absolute paths or relative paths.\n\n    Returns:\n        sorted_folders_paths (list): A list of folder paths.\n    \"\"\"\n    folder_path = Path(folder_path)\n    items = list(folder_path.iterdir())\n\n    folders = [item.resolve() for item in items if item.is_dir()]\n\n    sorted_folders = sorted(folders)\n\n    if not return_absolute_paths:\n        sorted_folders = [\n            folder.relative_to(folder_path) for folder in sorted_folders\n        ]\n\n    sorted_folders_paths = [str(file.as_posix()) for file in sorted_folders]\n\n    return sorted_folders_paths\n</code></pre>"},{"location":"common/file_utils/#kano.file_utils.print_foldertree","title":"<code>kano.file_utils.print_foldertree(folder_path, level=0, max_level=1, verbose=True)</code>","text":"<p>Print the folder tree structure.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>Path to the folder.</p> required <code>level</code> <code>int</code> <p>Current level to apply recursion, you do not need to provide this field.</p> <code>0</code> <code>max_level</code> <code>int</code> <p>Maximum level of folder tree.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional details.</p> <code>True</code> Source code in <code>kano\\file_utils.py</code> <pre><code>def print_foldertree(folder_path, level=0, max_level=1, verbose=True):\n    \"\"\"\n    Print the folder tree structure.\n\n    Args:\n        folder_path (str): Path to the folder.\n        level (int): Current level to apply recursion, you do not need to provide this field.\n        max_level (int): Maximum level of folder tree.\n        verbose (bool): Whether to print additional details.\n    \"\"\"\n    if level == 0:\n        current_line = f\"{folder_path} \"\n        if verbose:\n            current_line += get_folder_details(folder_path)\n        print(current_line)\n\n    files_paths, child_folders_paths = list_contents(folder_path)\n\n    if len(files_paths) &gt; 0:\n        print(\"|   \" * (level + 1))\n\n    for file_path in files_paths:\n        file_name = Path(file_path).name\n        current_line = \"|   \" * level + f\"|-- {file_name} \"\n        if verbose:\n            file_size = get_size(str(file_path), \"KB\")\n            current_line += f\"({file_size:.2f} KB)\"\n        print(current_line)\n\n    if len(child_folders_paths) &gt; 0:\n        print(\"|   \" * (level + 1))\n\n    for i, child_folder_path in enumerate(child_folders_paths):\n        child_folder_name = Path(child_folder_path).name\n        current_line = \"|   \" * level + f\"|-- {child_folder_name} \"\n        if verbose:\n            current_line += get_folder_details(child_folder_path)\n        print(current_line)\n        if level + 1 &lt; max_level:\n            print_foldertree(child_folder_path, level + 1, verbose)\n\n        if i + 1 &lt; len(child_folders_paths):\n            print(\"|   \" * (level + 1))\n</code></pre>"},{"location":"common/file_utils/#kano.file_utils.zip_paths","title":"<code>kano.file_utils.zip_paths(paths, output_zip)</code>","text":"<p>Create a ZIP file containing specified paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list</code> <p>List of file or folder paths to be included in the ZIP file.</p> required <code>output_zip</code> <code>str</code> <p>Path to save the output ZIP file.</p> required Source code in <code>kano\\file_utils.py</code> <pre><code>def zip_paths(paths, output_zip):\n    \"\"\"\n    Create a ZIP file containing specified paths.\n\n    Args:\n        paths (list): List of file or folder paths to be included in the ZIP file.\n        output_zip (str): Path to save the output ZIP file.\n    \"\"\"\n    with zipfile.ZipFile(output_zip, \"w\") as zipf:\n        for path in paths:\n            if os.path.isdir(path):\n                folder_path = path\n                for folder_root, _, files in os.walk(folder_path):\n                    for file in files:\n                        file_path = os.path.join(folder_root, file)\n                        arcname = os.path.relpath(file_path, folder_path)\n                        zipf.write(\n                            file_path,\n                            arcname=os.path.join(\n                                os.path.basename(folder_path), arcname\n                            ),\n                        )\n            elif os.path.isfile(path):\n                file_path = path\n                filename = os.path.basename(file_path)\n                zipf.write(file_path, arcname=filename)\n</code></pre>"},{"location":"common/file_utils/#kano.file_utils.create_folder","title":"<code>kano.file_utils.create_folder(folder_path)</code>","text":"<p>Create a folder if it doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>Path to the folder to be created.</p> required Source code in <code>kano\\file_utils.py</code> <pre><code>def create_folder(folder_path):\n    \"\"\"\n    Create a folder if it doesn't exist.\n\n    Args:\n        folder_path (str): Path to the folder to be created.\n    \"\"\"\n    os.makedirs(folder_path, exist_ok=True)\n</code></pre>"},{"location":"common/file_utils/#kano.file_utils.remove_folder","title":"<code>kano.file_utils.remove_folder(folder_path)</code>","text":"<p>Remove a folder and its contents.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>Path to the folder to be removed.</p> required Source code in <code>kano\\file_utils.py</code> <pre><code>def remove_folder(folder_path):\n    \"\"\"\n    Remove a folder and its contents.\n\n    Args:\n        folder_path (str): Path to the folder to be removed.\n    \"\"\"\n    try:\n        shutil.rmtree(folder_path)\n        print(f\"Folder '{folder_path}' and its contents removed successfully.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n</code></pre>"},{"location":"common/file_utils/#kano.file_utils.print_package_versions","title":"<code>kano.file_utils.print_package_versions(requirements_file_path='requirements.txt')</code>","text":"<p>Print packages listed in requirements file and their version in the current environment</p> <p>Parameters:</p> Name Type Description Default <code>requirements_file_path</code> <code>str</code> <p>path to a file contain packages names</p> <code>'requirements.txt'</code> Source code in <code>kano\\file_utils.py</code> <pre><code>def print_package_versions(requirements_file_path=\"requirements.txt\"):\n    \"\"\"\n    Print packages listed in requirements file and their version in the current environment\n\n    Args:\n        requirements_file_path (str): path to a file contain packages names\n    \"\"\"\n    package_names = get_package_names(requirements_file_path)\n    installed_versions = get_installed_versions(package_names)\n\n    for package_name, version in installed_versions.items():\n        if version is None:\n            print(f\"# {package_name}\")\n        else:\n            print(f\"{package_name}=={version}\")\n</code></pre>"},{"location":"common/image_utils/","title":"Image utilities","text":"<p>Kano provides some image-related functions:</p> <ul> <li><code>show_image</code>: show image from a file path or a numpy array.</li> <li><code>download_image</code>: download an image from the internet.</li> <li><code>get_randow_image</code>: download an image with desired size.</li> <li><code>rotate_image</code>: rotate an image around its center.</li> <li><code>concatenate_images</code>: concatenate a 2-dimensional list of images.</li> </ul>"},{"location":"common/image_utils/#kano.image.show_image","title":"<code>kano.image.show_image(image, figsize=(10, 10))</code>","text":"<p>Show image from a numpy array or a file path. Which can be used when run .py or .ipynb files.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Union[ndarray, str]</code> <p>a numpy array or a file path</p> required <code>figsize</code> <code>Tuple[int, int]</code> <p>(width, height) for image to show</p> <code>(10, 10)</code> Source code in <code>kano\\image\\utils.py</code> <pre><code>def show_image(image, figsize=(10, 10)):\n    \"\"\"\n    Show image from a numpy array or a file path.\n    Which can be used when run .py or .ipynb files.\n\n    Args:\n        image (Union[np.ndarray, str]): a numpy array or a file path\n        figsize (Tuple[int, int]): (width, height) for image to show\n    \"\"\"\n    if isinstance(image, str):\n        temp_image = cv2.imread(image)\n    else:\n        temp_image = image.copy()\n\n    plt.figure(figsize=figsize)\n    temp_image = cv2.cvtColor(temp_image.astype(np.uint8), cv2.COLOR_BGR2RGB)\n    plt.imshow(temp_image)\n    plt.show()\n</code></pre>"},{"location":"common/image_utils/#kano.image.download_image","title":"<code>kano.image.download_image(url, save_path=None)</code>","text":"<p>Download image from given url</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>url of the image</p> required <code>save_path</code> <code>str</code> <p>path to save image</p> <code>None</code> <p>Returns:</p> Name Type Description <code>image</code> <code>Union[ndarray, NoneType]</code> <p>return numpy array of the image if it's downloaded successfullly. Otherwise return None</p> Source code in <code>kano\\image\\utils.py</code> <pre><code>def download_image(url, save_path=None):\n    \"\"\"\n    Download image from given url\n\n    Args:\n        url (str): url of the image\n        save_path (str): path to save image\n\n    Returns:\n        image (Union[np.ndarray, NoneType]): return numpy array of the image if\n            it's downloaded successfullly. Otherwise return None\n    \"\"\"\n    response = requests.get(url)\n    if response.status_code == 200:\n        image_stream = BytesIO(response.content)\n        image_data = np.frombuffer(image_stream.read(), dtype=np.uint8)\n        image = cv2.imdecode(image_data, cv2.IMREAD_COLOR)\n\n        if save_path:\n            cv2.imwrite(save_path, image)\n\n        return image\n    else:\n        print(f\"Failed to download image from {url}\")\n        return None\n</code></pre>"},{"location":"common/image_utils/#kano.image.get_random_image","title":"<code>kano.image.get_random_image(width=400, height=300, save_path=None)</code>","text":"<p>Download a random image with desired size.</p> Source code in <code>kano\\image\\utils.py</code> <pre><code>def get_random_image(\n    width: int = 400, height: int = 300, save_path: Optional[str] = None\n) -&gt; Optional[np.ndarray]:\n    \"\"\"Download a random image with desired size.\"\"\"\n    return download_image(f\"https://picsum.photos/{width}/{height}\", save_path)\n</code></pre>"},{"location":"common/image_utils/#kano.image.rotate_image","title":"<code>kano.image.rotate_image(image, degree, expand=False)</code>","text":"<p>Rotate the given image with given degree</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>numpy array of the image</p> required <code>degree</code> <code>float</code> <p>total degrees to rotate</p> required <code>expand</code> <code>bool</code> <p>Pad rotated image with black color if True, otherwise return the cropped rotated image</p> <code>False</code> <p>Returns:</p> Name Type Description <code>rotated_image</code> <code>ndarray</code> <p>numpy array of the rotated image</p> Source code in <code>kano\\image\\process.py</code> <pre><code>def rotate_image(\n    image: np.ndarray, degree: float, expand: bool = False\n) -&gt; np.ndarray:\n    \"\"\"\n    Rotate the given image with given degree\n\n    Args:\n        image (np.ndarray): numpy array of the image\n        degree (float): total degrees to rotate\n        expand (bool): Pad rotated image with black color if True,\n            otherwise return the cropped rotated image\n\n    Returns:\n        rotated_image (np.ndarray): numpy array of the rotated image\n    \"\"\"\n    height, width = image.shape[:2]\n    center_point = (width / 2, height / 2)\n\n    rotation_matrix = cv2.getRotationMatrix2D(center_point, degree, 1.0)\n\n    new_height, new_width = image.shape[:2]\n    if expand:\n        abs_cos = abs(rotation_matrix[0, 0])\n        abs_sin = abs(rotation_matrix[0, 1])\n\n        new_width = int(height * abs_sin + width * abs_cos)\n        new_height = int(height * abs_cos + width * abs_sin)\n\n        rotation_matrix[0, 2] += new_width / 2 - center_point[0]\n        rotation_matrix[1, 2] += new_height / 2 - center_point[1]\n\n    rotated_image = cv2.warpAffine(\n        image, rotation_matrix, (new_width, new_height)\n    )\n\n    return rotated_image\n</code></pre>"},{"location":"common/image_utils/#kano.image.concatenate_images","title":"<code>kano.image.concatenate_images(image_list, padding_size=0)</code>","text":"<p>Concatenate images based on its appearance order in the given 2D list Each image will be padded to the max height, max width in the given list.</p> <p>Parameters:</p> Name Type Description Default <code>image_list</code> <code>list(list(np.ndarray</code> <p>2D (or 1D) list of images</p> required <code>padding_size</code> <code>int</code> <p>padding distance between each image</p> <code>0</code> <p>Returns:</p> Name Type Description <code>concatenated_image</code> <code>ndarray</code> <p>the concatenated image from 2D list</p> Source code in <code>kano\\image\\process.py</code> <pre><code>def concatenate_images(\n    image_list: List[List[np.ndarray]], padding_size: int = 0\n) -&gt; np.ndarray:\n    \"\"\"\n    Concatenate images based on its appearance order in the given 2D list\n    Each image will be padded to the max height, max width in the given list.\n\n    Args:\n        image_list (list(list(np.ndarray))): 2D (or 1D) list of images\n        padding_size (int): padding distance between each image\n\n    Returns:\n        concatenated_image (np.ndarray): the concatenated image from 2D list\n    \"\"\"\n\n    # ensure image_list is a 2D list\n    new_image_list = copy.deepcopy(image_list)\n    if not isinstance(image_list[0], list):\n        new_image_list = [copy.deepcopy(image_list)]\n\n    rows = len(new_image_list)\n    cols = max(len(row) for row in new_image_list)\n\n    for image_row in new_image_list:\n        image_row += [None] * (cols - len(image_row))\n\n    # pad every images\n    max_height = max(\n        image.shape[0]\n        for row in new_image_list\n        for image in row\n        if image is not None\n    )\n    max_width = max(\n        image.shape[1]\n        for row in new_image_list\n        for image in row\n        if image is not None\n    )\n\n    padded_image_list = list()\n    for i, row in enumerate(new_image_list):\n        padded_image_list.append(list())\n        for j, image in enumerate(row):\n            padded_image = np.zeros((max_height, max_width, 3), dtype=np.uint8)\n            if image is not None:\n                padded_image = pad_image(image, (max_height, max_width))\n            padded_image_list[i].append(padded_image)\n\n    concatenated_image = np.zeros(\n        (\n            max_height * rows + padding_size * (rows - 1),\n            max_width * cols + padding_size * (cols - 1),\n            3,\n        ),\n        dtype=np.uint8,\n    )\n\n    for i, row in enumerate(padded_image_list):\n        for j, image in enumerate(row):\n\n            h, w, _ = image.shape\n            concatenated_image[\n                (i &gt; 0) * padding_size\n                + i * max_height : (i &gt; 0) * padding_size\n                + i * max_height\n                + h,\n                (j &gt; 0) * padding_size\n                + j * max_width : (j &gt; 0) * padding_size\n                + j * max_width\n                + w,\n            ] = image\n\n    return concatenated_image\n</code></pre>"},{"location":"common/video_utils/","title":"Video utilities","text":"<p>Kano provides some video-related functions:</p> <ul> <li><code>get_frame_at_second</code>: get a frame at the given second of a video.</li> <li><code>extract_frames</code>: save frames of a video.</li> <li><code>cut_video</code>: save a part of a video.</li> <li><code>concatenate_videos</code>: concatenate a 2-dimensional list of videos.</li> </ul>"},{"location":"common/video_utils/#kano.video_utils.get_frame_at_second","title":"<code>kano.video_utils.get_frame_at_second(video_path, target_second)</code>","text":"<p>Get numpy array of a frame from a video at the given second</p> <p>Parameters:</p> Name Type Description Default <code>video_path</code> <code>str</code> <p>path of the video</p> required <code>target_second</code> <code>int</code> <p>second timestamp to get frame</p> required <p>Returns:</p> Name Type Description <code>frame</code> <code>ndarray</code> <p>numpy array of the frame at the given second</p> Source code in <code>kano\\video_utils.py</code> <pre><code>def get_frame_at_second(video_path, target_second):\n    \"\"\"\n    Get numpy array of a frame from a video at the given second\n\n    Args:\n        video_path (str): path of the video\n        target_second (int): second timestamp to get frame\n\n    Returns:\n        frame (np.ndarray): numpy array of the frame at the given second\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n\n    if not cap.isOpened():\n        raise ValueError(\"Video file could not be opened.\")\n\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    target_frame = int(target_second * fps)\n\n    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)\n\n    ret, frame = cap.read()\n\n    cap.release()\n\n    if ret:\n        return frame\n    else:\n        raise ValueError(\"Frame not found at the specified second.\")\n</code></pre>"},{"location":"common/video_utils/#kano.video_utils.extract_frames","title":"<code>kano.video_utils.extract_frames(video_path, target_folder, seconds_interval)</code>","text":"<p>Extract frames from a video with a given seconds interval</p> <p>Parameters:</p> Name Type Description Default <code>video_path</code> <code>str</code> <p>path of the video</p> required <code>target_folder</code> <code>str</code> <p>path to save extracted frames</p> required <code>seconds_interval</code> <code>float</code> <p>amount of seconds between two extracted frames</p> required Source code in <code>kano\\video_utils.py</code> <pre><code>def extract_frames(video_path, target_folder, seconds_interval):\n    \"\"\"\n    Extract frames from a video with a given seconds interval\n\n    Args:\n        video_path (str): path of the video\n        target_folder (str): path to save extracted frames\n        seconds_interval (float): amount of seconds between two extracted frames\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    video_fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_interval = int(video_fps * seconds_interval)\n\n    create_folder(target_folder)\n\n    max_length = len(str(frame_count))\n    for frame_number in tqdm.tqdm(range(0, frame_count, frame_interval)):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n        ret, frame = cap.read()\n        if not ret:\n            break\n        number = str(frame_number).zfill(max_length)\n        frame_filename = os.path.join(target_folder, f\"frame_{number}.jpg\")\n        cv2.imwrite(frame_filename, frame)\n\n    cap.release()\n</code></pre>"},{"location":"common/video_utils/#kano.video_utils.cut_video","title":"<code>kano.video_utils.cut_video(input_video_path, output_video_path, start_second, end_second)</code>","text":"<p>Cut a segment from a video file and save it as a new video.</p> <p>Parameters:</p> Name Type Description Default <code>input_video_path</code> <code>str</code> <p>Path to the input video file.</p> required <code>output_video_path</code> <code>str</code> <p>Path to save the output video file.</p> required <code>start_second</code> <code>float</code> <p>Start time of the segment to be cut in seconds.</p> required <code>end_second</code> <code>float</code> <p>End time of the segment to be cut in seconds.</p> required Source code in <code>kano\\video_utils.py</code> <pre><code>def cut_video(input_video_path, output_video_path, start_second, end_second):\n    \"\"\"\n    Cut a segment from a video file and save it as a new video.\n\n    Args:\n        input_video_path (str): Path to the input video file.\n        output_video_path (str): Path to save the output video file.\n        start_second (float): Start time of the segment to be cut in seconds.\n        end_second (float): End time of the segment to be cut in seconds.\n    \"\"\"\n    cap = cv2.VideoCapture(input_video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    start_frame = int(start_second * fps)\n    end_frame = int(end_second * fps)\n\n    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\n    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n    while cap.isOpened() and cap.get(cv2.CAP_PROP_POS_FRAMES) &lt;= end_frame:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        out.write(frame)\n\n    cap.release()\n    out.release()\n</code></pre>"},{"location":"common/video_utils/#kano.video_utils.concatenate_videos","title":"<code>kano.video_utils.concatenate_videos(video_paths, titles=None, output_video_path='concatenated_video.mp4', total_seconds=None, font_scale=2, font_thickness=3, title_padding_size=10, frame_padding_size=10)</code>","text":"<p>Concatenate multiple video files into a single video.</p> <p>Parameters:</p> Name Type Description Default <code>video_paths</code> <code>list</code> <p>A 2D list of video file paths to be concatenated.</p> required <code>titles</code> <code>list</code> <p>A 2D list of titles corresponding to each video segment.</p> <code>None</code> <code>output_video_path</code> <code>str</code> <p>Path to save the concatenated video file.</p> <code>'concatenated_video.mp4'</code> <code>total_seconds</code> <code>float</code> <p>Total duration of the output video in seconds.</p> <code>None</code> <code>font_scale</code> <code>int</code> <p>Font scale for titles.</p> <code>2</code> <code>font_thickness</code> <code>int</code> <p>Font thickness for titles.</p> <code>3</code> <code>title_padding_size</code> <code>int</code> <p>Padding size for titles.</p> <code>10</code> <code>frame_padding_size</code> <code>int</code> <p>Padding size between frames.</p> <code>10</code> Source code in <code>kano\\video_utils.py</code> <pre><code>def concatenate_videos(\n    video_paths,\n    titles=None,\n    output_video_path=\"concatenated_video.mp4\",\n    total_seconds=None,\n    font_scale=2,\n    font_thickness=3,\n    title_padding_size=10,\n    frame_padding_size=10,\n):\n    \"\"\"\n    Concatenate multiple video files into a single video.\n\n    Args:\n        video_paths (list): A 2D list of video file paths to be concatenated.\n        titles (list): A 2D list of titles corresponding to each video segment.\n        output_video_path (str): Path to save the concatenated video file.\n        total_seconds (float): Total duration of the output video in seconds.\n        font_scale (int): Font scale for titles.\n        font_thickness (int): Font thickness for titles.\n        title_padding_size (int): Padding size for titles.\n        frame_padding_size (int): Padding size between frames.\n    \"\"\"\n    # ensure video_paths is a 2D list\n    new_video_paths = copy.deepcopy(video_paths)\n    if not isinstance(video_paths[0], list):\n        new_video_paths = [copy.deepcopy(video_paths)]\n\n    rows = len(new_video_paths)\n    cols = max(len(row) for row in new_video_paths)\n\n    for video_path in new_video_paths:\n        video_path += [None] * (cols - len(video_path))\n\n    # get target video duration\n    video_captures = list()\n    durations = list()\n\n    max_width = 0\n    max_height = 0\n    sample_cap = None\n    for i, row in enumerate(new_video_paths):\n        video_captures.append(list())\n        for video_path in row:\n            if video_path is not None:\n                sample_cap = cv2.VideoCapture(video_path)\n                width = int(sample_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n                height = int(sample_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n                max_width = max(width, max_width)\n                max_height = max(height, max_height)\n                video_captures[i].append(sample_cap)\n                durations.append(get_video_duration(video_path))\n            else:\n                video_captures[i].append(None)\n\n    min_duration = min(durations)\n    if total_seconds is not None:\n        min_duration = min(min_duration, total_seconds)\n\n    # init output video\n    fps = int(sample_cap.get(cv2.CAP_PROP_FPS))\n    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    text_size = cv2.getTextSize(\"SAMPLE\", font, font_scale, font_thickness)[0]\n\n    output_width = max_width * cols + frame_padding_size * (cols - 1)\n    output_height = (\n        max_height + (text_size[1] + title_padding_size * 2)\n    ) * rows + frame_padding_size * (rows - 1)\n\n    output_video = cv2.VideoWriter(\n        output_video_path, fourcc, fps, (output_width, output_height)\n    )\n    num_frames = int(min_duration * fps)\n\n    for __ in tqdm.tqdm(range(num_frames), desc=\"Videos concatenating\"):\n        frames = list()\n        for row in range(rows):\n            frames.append(list())\n            for col in range(cols):\n                cap = video_captures[row][col]\n                if (\n                    len(titles) &lt; row + 1\n                    or len(titles[row]) &lt; col + 1\n                    or titles[row][col] is None\n                ):\n                    title = \" \"\n                else:\n                    title = titles[row][col]\n\n                frame = np.zeros((max_height, max_width, 3), dtype=np.uint8)\n                if cap is not None:\n                    __, frame = cap.read()\n\n                frame = add_title(\n                    frame,\n                    title,\n                    font_scale,\n                    font_thickness,\n                    title_padding_size,\n                )\n\n                frames[row].append(frame)\n\n        concatenated_frame = concatenate_images(frames, frame_padding_size)\n\n        output_video.write(concatenated_frame)\n\n    for row_caps in video_captures:\n        for cap in row_caps:\n            if cap is not None:\n                cap.release()\n\n    output_video.release()\n</code></pre>"},{"location":"cv/","title":"Computer Vision Utilities","text":"<p>Kano currently offers classes for handling YOLO-formatted datasets, one of the most commonly used formats in Object Detection tasks. With the <code>YoloImage</code> and <code>YoloDataset</code> classes, developers can load, explore, merge, split, and rename their datasets. Here are some examples:</p> <p>Test demo with Google Colab here: </p>"},{"location":"cv/#yolo-formatted-dataset-tasks","title":"YOLO-formatted dataset tasks","text":"<p>Note</p> <p>A valid YOLO-formatted dataset will have a folder tree like this <pre><code>    dataset_name:\n    \u251c\u2500 train\n    |  \u251c\u2500 images\n    |  |  \u251c\u2500 image1.jpg\n    |  |  \u2514\u2500 ...\n    |  \u2514\u2500 labels\n    |     \u251c\u2500 image1.txt\n    |     \u2514\u2500 ...\n    \u251c\u2500 valid (optional)\n    \u251c\u2500 test (optional)\n    \u2514\u2500 data.yaml (must include a list of classes names inside \"names\" field)\n</code></pre></p>"},{"location":"cv/#load-and-show-a-yolo-image","title":"Load and show a YOLO image","text":"<pre><code>from kano.dataset_utils import YoloImage\n\n\nlabel_dict = {0: \"dog\"}\nimage_path = \"/content/dog_detection/train/images/dog_1_jpg.rf.dc6fff7fee9b6fb637b890b8387c6ce0.jpg\"\nimage = YoloImage(image_path, label_dict)\nimage.show_image()\nimage.show_annotated_image()\n\n# or you can get the annotated image and show\nfrom kano.image import show_image\n\n\nannotated_image = image.get_annotated_image()\nshow_image(annotated_image)\n</code></pre> <p>Result:</p> <p>Original image: </p> <p>Annotated image: </p>"},{"location":"cv/#load-and-show-summary-of-a-yolo-dataset","title":"Load and show summary of a YOLO dataset","text":"<pre><code>from kano.dataset_utils import YoloDataset\n\n\ndataset_path = \"/content/cat_detection\"\ndataset = YoloDataset(dataset_path)\n\n# print summary information\ndataset.summary()\n\n# plot sample images\ndataset.show_sample()\n</code></pre> <p>Result:</p> <p><pre><code>Summary dataset cat_detection:\n- Classes:  ['cat']\n- Subsets:\n  + train: 1 images\n  + test: 1 images\n- Total images: 2\n</code></pre> </p>"},{"location":"cv/#merge-datasets","title":"Merge datasets","text":"<p>When merging datasets, the names are also merged and reindexed alphabetically. The training images will be saved in the train folder, and similarly for the validation and test folders.</p> <pre><code>from kano.dataset_utils import YoloDataset\n\n\ndatasets_paths = [\"cat_detection\", \"dog_detection\"]\nmerged_dataset_path = \"animals_detection\"\n\nYoloDataset.merge_datasets(datasets_paths, merged_dataset_path)\n\nYoloDataset(merged_dataset_path).show_sample()\n</code></pre> <p>Result:</p> <pre><code>Input datasets:\nSummary dataset cat_detection:\n- Classes:  ['cat']\n- Subsets:\n  + train: 1 images\n  + test: 1 images\n- Total images: 2\nSummary dataset dog_detection:\n- Classes:  ['dog']\n- Subsets:\n  + train: 1 images\n  + valid: 1 images\n- Total images: 2\nMerged dataset:\nSummary dataset animals_detection:\n- Classes:  ['cat', 'dog']\n- Subsets:\n  + train: 2 images\n  + valid: 1 images\n  + test: 1 images\n- Total images: 4\n</code></pre> <p></p>"},{"location":"cv/#split-train-validation-test-datasets","title":"Split train, validation, test datasets","text":"<pre><code>from kano.dataset_utils import YoloDataset\n\n\ndataset = YoloDataset(\"animals_detection\")\ndataset.split(\"splitted_dataset\", ratios=[0.4, 0.3])\n</code></pre> <p>Result:</p> <pre><code>Summary dataset animals_detection:\n- Classes:  ['cat', 'dog']\n- Subsets:\n  + train: 2 images\n  + valid: 1 images\n  + test: 1 images\n- Total images: 4\nSummary dataset splitted_dataset:\n- Classes:  ['cat', 'dog']\n- Subsets:\n  + train: 1 images\n  + valid: 1 images\n  + test: 2 images\n- Total images: 4\n</code></pre>"},{"location":"cv/#rename-classes","title":"Rename classes","text":"<p>Classes can be removed by renaming to <code>None</code>.</p> <pre><code>from kano.dataset_utils import YoloDataset\n\n\nrenamed_dataset_path = \"renamed_dataset\"\nrenaming_dict = {\"cat\": \"animal\", \"dog\": None}\n\ndataset = YoloDataset(\"animals_detection\")\ndataset.rename_classes(renamed_dataset_path, renaming_dict)\n\nrenamed_dataset = YoloDataset(renamed_dataset_path)\nrenamed_dataset.show_sample()\n</code></pre> <p>Result</p> <pre><code>Summary dataset animals_detection:\n- Classes:  ['cat', 'dog']\n- Subsets:\n  + train: 2 images\n  + valid: 1 images\n  + test: 1 images\n- Total images: 4\nClasses after renaming: ['animal']\nSummary dataset renamed_dataset:\n- Classes:  ['animal']\n- Subsets:\n  + train: 2 images\n  + valid: 1 images\n  + test: 1 images\n- Total images: 4\n</code></pre> <p></p>"},{"location":"cv/#object-detection-tasks","title":"Object Detection tasks","text":""},{"location":"cv/#draw-bounding-box","title":"Draw bounding box","text":"<p>You can add label for the bounding box. Current supported types of box are <code>xyxy</code>, <code>xywh</code>, <code>s_xywh</code> (scaled <code>xywh</code>).</p> <pre><code>import cv2\nfrom kano.image import show_image\nfrom kano.detect_utils import draw_bbox\n\n\nimage_path = \"/content/dog_detection/train/images/dog_1_jpg.rf.dc6fff7fee9b6fb637b890b8387c6ce0.jpg\"\nimage = cv2.imread(image_path)\n\nlabel = \"a cute dog\"\nbbox = [112, 326, 980, 827]\n\nannotated_image = draw_bbox(image, bbox, bbox_type=\"xyxy\", label=label, bbox_color=(0, 0, 255))\nshow_image(annotated_image)\n</code></pre> <p>Result:</p> <p></p>"},{"location":"cv/dataset_utils/","title":"Dataset utilities","text":"<p>Kano provides some classes to visualize and manipulate YOLO-formatted datasets.</p> <p>Note</p> <p>A valid YOLO-formatted dataset will have a folder tree like this <pre><code>    dataset_name:\n    \u251c\u2500 train\n    |  \u251c\u2500 images\n    |  |  \u251c\u2500 image1.jpg\n    |  |  \u2514\u2500 ...\n    |  \u2514\u2500 labels\n    |     \u251c\u2500 image1.txt\n    |     \u2514\u2500 ...\n    \u251c\u2500 valid (optional)\n    \u251c\u2500 test (optional)\n    \u2514\u2500 data.yaml (must include a list of classes names inside \"names\" field)\n</code></pre></p> <ul> <li><code>YoloImage</code>: visualize, copy a Yolo-formmated image.</li> <li><code>YoloDataset</code>: visualize, merge, split Yolo-formatted datasets.</li> </ul>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage","title":"<code>kano.dataset_utils.YoloImage</code>","text":"<p>Represents an image annotated in YOLO format, which includes bounding boxes or skeletons.</p> <p>Attributes:</p> Name Type Description <code>image</code> <code>ndarray</code> <p>The original image.</p> <code>image_path</code> <code>str</code> <p>Path to the image file.</p> <code>label_path</code> <code>str</code> <p>Path to the label file corresponding to the image.</p> <code>task</code> <code>str</code> <p>Task type, either \"detect\" or \"pose\".</p> <code>labels</code> <code>list</code> <p>List of dictionaries containing label information.</p> <code>labels_dict</code> <code>dict</code> <p>Dictionary mapping class IDs to class names.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>class YoloImage:\n    \"\"\"\n    Represents an image annotated in YOLO format, which includes bounding boxes or skeletons.\n\n    Attributes:\n        image (numpy.ndarray): The original image.\n        image_path (str): Path to the image file.\n        label_path (str): Path to the label file corresponding to the image.\n        task (str): Task type, either \"detect\" or \"pose\".\n        labels (list): List of dictionaries containing label information.\n        labels_dict (dict): Dictionary mapping class IDs to class names.\n    \"\"\"\n\n    def __init__(self, image_path, labels_dict=None, task=\"detect\"):\n        \"\"\"\n        Initialize a YoloImage object.\n\n        Args:\n            image_path (str): Path to the image file.\n            labels_dict (dict): Dictionary mapping class IDs to class names.\n            task (str): Task type. Possible values: \"detect\", \"pose\".\n        \"\"\"\n        self.image = cv2.imread(image_path)\n        self.image_path = image_path\n        if task not in TASKS:\n            raise ValueError(\"Unexpected task. Please provide one of:\", TASKS)\n        self.task = task\n        self.labels = self.get_labels()\n        self.labels_dict = labels_dict\n\n    def get_label_path(self, image_path):\n        \"\"\"\n        Get the path to the label file corresponding to the given image.\n\n        Args:\n            image_path (str): Path to the image file.\n\n        Returns:\n            label_path (str): Path to the label file.\n        \"\"\"\n        image_path = Path(image_path)\n        images_folder_path = image_path.parent\n        dataset_path = images_folder_path.parent\n        labels_folder_path = dataset_path / \"labels\"\n        label_filename = image_path.with_suffix(\".txt\").name\n        label_path = labels_folder_path / label_filename\n\n        return str(label_path)\n\n    def get_labels(self):\n        \"\"\"\n        Parse the label file and extract label information.\n        Each label can contain:\n            - class: class of the object\n            - s_xywh: scaled xywh box\n            - xyxy: xyxy box\n            - keypoints: list of dict(xy, state) for pose estimation tasks\n\n        Returns:\n            labels (list): List of dictionaries, each containing label information.\n        \"\"\"\n        self.label_path = self.get_label_path(self.image_path)\n        labels = list()\n        image_height, image_width = self.image.shape[:2]\n        with open(self.label_path, \"r\") as file:\n            for line in file:\n                line = line.strip().split()\n                label = {\n                    \"class\": int(line[0]),\n                    \"s_xywh\": np.array([float(x) for x in line[1:5]]),\n                }\n                xywh = label[\"s_xywh\"].copy() * np.array(\n                    [image_width, image_height, image_width, image_height]\n                )\n                label[\"xyxy\"] = xywh2xyxy(xywh)\n\n                if self.task == \"pose\":\n                    keypoints = list()\n                    for start_id in range(5, len(line), 3):\n                        # \"state\" in [0, 1, 2] with:\n                        # - 0: deleted\n                        # - 1: occluded\n                        # - 2: visible\n                        x = int(float(line[start_id]) * image_width)\n                        y = int(float(line[start_id + 1]) * image_height)\n                        state = int(float(line[start_id + 2]))\n                        keypoints.append(\n                            {\n                                \"xy\": (x, y),\n                                \"state\": state,\n                            }\n                        )\n                    label[\"keypoints\"] = keypoints\n\n                labels.append(label)\n        return labels\n\n    def show_image(self, figsize=(10, 10)):\n        \"\"\"\n        Display the original image.\n\n        Args:\n            figsize (tuple(int, int)): Size of the figure (width, height) in inches.\n        \"\"\"\n        show_image(self.image, figsize)\n\n    def get_annotated_image(self):\n        \"\"\"\n        Get the annotated image with bounding boxes or skeletons drawn.\n\n        Returns:\n            annotated_image (np.ndarray): Annotated image.\n        \"\"\"\n        annotated_image = self.image.copy()\n        for label in self.labels:\n\n            if self.task == \"pose\":\n                annotated_image = draw_skeleton(\n                    annotated_image, label[\"keypoints\"]\n                )\n\n            cls = label[\"class\"]\n            if self.labels_dict is not None:\n                cls = self.labels_dict[cls]\n            bbox = label[\"s_xywh\"]\n\n            annotated_image = draw_bbox(\n                annotated_image, bbox, \"s_xywh\", (0, 255, 0), str(cls)\n            )\n\n        return annotated_image\n\n    def show_annotated_image(self, figsize=(10, 10)):\n        \"\"\"\n        Display the annotated image with bounding boxes or skeletons drawn.\n\n        Returns:\n            figsize (tuple(int, int)): Size of the figure (width, height) in inches.\n        \"\"\"\n        annotated_image = self.get_annotated_image()\n        show_image(annotated_image, figsize)\n\n    def copy_to(\n        self,\n        target_folder_path,\n        prefix=\"\",\n        reindex_dict=None,\n        target_stem=None,\n    ):\n        \"\"\"\n        Copy the image and its label file to the specified target folder.\n\n        Returns:\n            target_folder_path (str): Path to the target folder.\n            prefix (str): Prefix to be added to the filenames\n            reindex_dict (dict): Dictionary mapping original class IDs to new class IDs.\n            target_stem (str): Name stem for the copied files\n        \"\"\"\n        source_image_path = Path(self.image_path)\n        source_label_path = Path(self.label_path)\n        target_folder_path = Path(target_folder_path)\n\n        if target_stem is None:\n            target_image_path = (\n                target_folder_path\n                / \"images\"\n                / (prefix + source_image_path.name)\n            )\n            target_label_path = (\n                target_folder_path\n                / \"labels\"\n                / (prefix + source_label_path.name)\n            )\n        else:\n            target_image_path = (\n                target_folder_path / \"images\" / (target_stem + \".jpg\")\n            )\n            target_label_path = (\n                target_folder_path / \"labels\" / (target_stem + \".txt\")\n            )\n\n        shutil.copyfile(self.image_path, str(target_image_path))\n        shutil.copyfile(self.label_path, str(target_label_path))\n\n        if reindex_dict:\n            with open(str(source_label_path), \"r\") as f:\n                lines = f.readlines()\n\n            new_lines = list()\n            for line in lines:\n                class_id = int(line.split()[0])\n                if class_id in reindex_dict:\n                    new_class_id = reindex_dict[class_id]\n                    if new_class_id is not None:\n                        new_line = (\n                            f\"{new_class_id} {' '.join(line.split()[1:])}\\n\"\n                        )\n                        new_lines.append(new_line)\n\n            with open(str(target_label_path), \"w\") as f:\n                f.writelines(new_lines)\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.__init__","title":"<code>__init__(image_path, labels_dict=None, task='detect')</code>","text":"<p>Initialize a YoloImage object.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Path to the image file.</p> required <code>labels_dict</code> <code>dict</code> <p>Dictionary mapping class IDs to class names.</p> <code>None</code> <code>task</code> <code>str</code> <p>Task type. Possible values: \"detect\", \"pose\".</p> <code>'detect'</code> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def __init__(self, image_path, labels_dict=None, task=\"detect\"):\n    \"\"\"\n    Initialize a YoloImage object.\n\n    Args:\n        image_path (str): Path to the image file.\n        labels_dict (dict): Dictionary mapping class IDs to class names.\n        task (str): Task type. Possible values: \"detect\", \"pose\".\n    \"\"\"\n    self.image = cv2.imread(image_path)\n    self.image_path = image_path\n    if task not in TASKS:\n        raise ValueError(\"Unexpected task. Please provide one of:\", TASKS)\n    self.task = task\n    self.labels = self.get_labels()\n    self.labels_dict = labels_dict\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.copy_to","title":"<code>copy_to(target_folder_path, prefix='', reindex_dict=None, target_stem=None)</code>","text":"<p>Copy the image and its label file to the specified target folder.</p> <p>Returns:</p> Name Type Description <code>target_folder_path</code> <code>str</code> <p>Path to the target folder.</p> <code>prefix</code> <code>str</code> <p>Prefix to be added to the filenames</p> <code>reindex_dict</code> <code>dict</code> <p>Dictionary mapping original class IDs to new class IDs.</p> <code>target_stem</code> <code>str</code> <p>Name stem for the copied files</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def copy_to(\n    self,\n    target_folder_path,\n    prefix=\"\",\n    reindex_dict=None,\n    target_stem=None,\n):\n    \"\"\"\n    Copy the image and its label file to the specified target folder.\n\n    Returns:\n        target_folder_path (str): Path to the target folder.\n        prefix (str): Prefix to be added to the filenames\n        reindex_dict (dict): Dictionary mapping original class IDs to new class IDs.\n        target_stem (str): Name stem for the copied files\n    \"\"\"\n    source_image_path = Path(self.image_path)\n    source_label_path = Path(self.label_path)\n    target_folder_path = Path(target_folder_path)\n\n    if target_stem is None:\n        target_image_path = (\n            target_folder_path\n            / \"images\"\n            / (prefix + source_image_path.name)\n        )\n        target_label_path = (\n            target_folder_path\n            / \"labels\"\n            / (prefix + source_label_path.name)\n        )\n    else:\n        target_image_path = (\n            target_folder_path / \"images\" / (target_stem + \".jpg\")\n        )\n        target_label_path = (\n            target_folder_path / \"labels\" / (target_stem + \".txt\")\n        )\n\n    shutil.copyfile(self.image_path, str(target_image_path))\n    shutil.copyfile(self.label_path, str(target_label_path))\n\n    if reindex_dict:\n        with open(str(source_label_path), \"r\") as f:\n            lines = f.readlines()\n\n        new_lines = list()\n        for line in lines:\n            class_id = int(line.split()[0])\n            if class_id in reindex_dict:\n                new_class_id = reindex_dict[class_id]\n                if new_class_id is not None:\n                    new_line = (\n                        f\"{new_class_id} {' '.join(line.split()[1:])}\\n\"\n                    )\n                    new_lines.append(new_line)\n\n        with open(str(target_label_path), \"w\") as f:\n            f.writelines(new_lines)\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.get_annotated_image","title":"<code>get_annotated_image()</code>","text":"<p>Get the annotated image with bounding boxes or skeletons drawn.</p> <p>Returns:</p> Name Type Description <code>annotated_image</code> <code>ndarray</code> <p>Annotated image.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def get_annotated_image(self):\n    \"\"\"\n    Get the annotated image with bounding boxes or skeletons drawn.\n\n    Returns:\n        annotated_image (np.ndarray): Annotated image.\n    \"\"\"\n    annotated_image = self.image.copy()\n    for label in self.labels:\n\n        if self.task == \"pose\":\n            annotated_image = draw_skeleton(\n                annotated_image, label[\"keypoints\"]\n            )\n\n        cls = label[\"class\"]\n        if self.labels_dict is not None:\n            cls = self.labels_dict[cls]\n        bbox = label[\"s_xywh\"]\n\n        annotated_image = draw_bbox(\n            annotated_image, bbox, \"s_xywh\", (0, 255, 0), str(cls)\n        )\n\n    return annotated_image\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.get_label_path","title":"<code>get_label_path(image_path)</code>","text":"<p>Get the path to the label file corresponding to the given image.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Path to the image file.</p> required <p>Returns:</p> Name Type Description <code>label_path</code> <code>str</code> <p>Path to the label file.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def get_label_path(self, image_path):\n    \"\"\"\n    Get the path to the label file corresponding to the given image.\n\n    Args:\n        image_path (str): Path to the image file.\n\n    Returns:\n        label_path (str): Path to the label file.\n    \"\"\"\n    image_path = Path(image_path)\n    images_folder_path = image_path.parent\n    dataset_path = images_folder_path.parent\n    labels_folder_path = dataset_path / \"labels\"\n    label_filename = image_path.with_suffix(\".txt\").name\n    label_path = labels_folder_path / label_filename\n\n    return str(label_path)\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.get_labels","title":"<code>get_labels()</code>","text":"<p>Parse the label file and extract label information. Each label can contain:     - class: class of the object     - s_xywh: scaled xywh box     - xyxy: xyxy box     - keypoints: list of dict(xy, state) for pose estimation tasks</p> <p>Returns:</p> Name Type Description <code>labels</code> <code>list</code> <p>List of dictionaries, each containing label information.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def get_labels(self):\n    \"\"\"\n    Parse the label file and extract label information.\n    Each label can contain:\n        - class: class of the object\n        - s_xywh: scaled xywh box\n        - xyxy: xyxy box\n        - keypoints: list of dict(xy, state) for pose estimation tasks\n\n    Returns:\n        labels (list): List of dictionaries, each containing label information.\n    \"\"\"\n    self.label_path = self.get_label_path(self.image_path)\n    labels = list()\n    image_height, image_width = self.image.shape[:2]\n    with open(self.label_path, \"r\") as file:\n        for line in file:\n            line = line.strip().split()\n            label = {\n                \"class\": int(line[0]),\n                \"s_xywh\": np.array([float(x) for x in line[1:5]]),\n            }\n            xywh = label[\"s_xywh\"].copy() * np.array(\n                [image_width, image_height, image_width, image_height]\n            )\n            label[\"xyxy\"] = xywh2xyxy(xywh)\n\n            if self.task == \"pose\":\n                keypoints = list()\n                for start_id in range(5, len(line), 3):\n                    # \"state\" in [0, 1, 2] with:\n                    # - 0: deleted\n                    # - 1: occluded\n                    # - 2: visible\n                    x = int(float(line[start_id]) * image_width)\n                    y = int(float(line[start_id + 1]) * image_height)\n                    state = int(float(line[start_id + 2]))\n                    keypoints.append(\n                        {\n                            \"xy\": (x, y),\n                            \"state\": state,\n                        }\n                    )\n                label[\"keypoints\"] = keypoints\n\n            labels.append(label)\n    return labels\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.show_annotated_image","title":"<code>show_annotated_image(figsize=(10, 10))</code>","text":"<p>Display the annotated image with bounding boxes or skeletons drawn.</p> <p>Returns:</p> Name Type Description <code>figsize</code> <code>tuple(int, int)</code> <p>Size of the figure (width, height) in inches.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def show_annotated_image(self, figsize=(10, 10)):\n    \"\"\"\n    Display the annotated image with bounding boxes or skeletons drawn.\n\n    Returns:\n        figsize (tuple(int, int)): Size of the figure (width, height) in inches.\n    \"\"\"\n    annotated_image = self.get_annotated_image()\n    show_image(annotated_image, figsize)\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloImage.show_image","title":"<code>show_image(figsize=(10, 10))</code>","text":"<p>Display the original image.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>tuple(int, int</code> <p>Size of the figure (width, height) in inches.</p> <code>(10, 10)</code> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def show_image(self, figsize=(10, 10)):\n    \"\"\"\n    Display the original image.\n\n    Args:\n        figsize (tuple(int, int)): Size of the figure (width, height) in inches.\n    \"\"\"\n    show_image(self.image, figsize)\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset","title":"<code>kano.dataset_utils.YoloDataset</code>","text":"<p>Dataset class with Yolo format.</p> <p>Attributes:</p> Name Type Description <code>dataset_path</code> <code>Path</code> <p>path to the dataset folder</p> <code>name</code> <code>str</code> <p>name of the dataset (folder name)</p> <code>classes</code> <code>list(str</code> <p>names of classes in the dataset</p> <code>task</code> <code>str</code> <p>dataset usecase, must be a task in [\"detect\", \"pose\"]</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>class YoloDataset:\n    \"\"\"\n    Dataset class with Yolo format.\n\n    Attributes:\n        dataset_path (Path): path to the dataset folder\n        name (str): name of the dataset (folder name)\n        classes (list(str)): names of classes in the dataset\n        task (str): dataset usecase, must be a task in [\"detect\", \"pose\"]\n    \"\"\"\n\n    def __init__(self, dataset_path, task=\"detect\"):\n        \"\"\"\n        Initialize a YoloDataset object.\n\n        Returns:\n            dataset_path (str): Path to the dataset folder.\n            task (str): . Dataset use case. Default is \"detect\".\n                        Possible values: \"detect\", \"pose\".\n        \"\"\"\n        self.dataset_path = Path(dataset_path)\n        self.name = self.dataset_path.name\n        self.train_folder = self.dataset_path / \"train\"\n        self.valid_folder = self.dataset_path / \"valid\"\n        self.test_folder = self.dataset_path / \"test\"\n        self.classes = self.get_classes(str(self.dataset_path / \"data.yaml\"))\n        if task not in TASKS:\n            raise ValueError(\"Unexpected task. Please provide one of:\", TASKS)\n        self.task = task\n\n    @classmethod\n    def get_classes(cls, yaml_path):\n        \"\"\"\n        Retrieve classes from a YAML file.\n\n        Returns:\n            yaml_path (str): Path to the YAML file containing class names.\n\n        Returns:\n            names (list(str)): List of class names.\n        \"\"\"\n        with open(yaml_path, \"r\") as file:\n            data = yaml.safe_load(file)\n        return data[\"names\"]\n\n    def summary(self, count_box=False):\n        \"\"\"\n        Print summary information about the dataset.\n        \"\"\"\n        print(f\"Summary dataset {self.dataset_path.name}:\")\n        print(\"- Classes: \", self.classes)\n\n        if count_box:\n            print(\n                \"  *Note: the box counting can take a long time depend on dataset size, please wait...\"\n            )\n            images_paths = list()\n            for folder_path in [\n                self.train_folder,\n                self.valid_folder,\n                self.test_folder,\n            ]:\n                if folder_path.exists():\n                    images_paths += list_files(str(folder_path / \"images\"))\n\n            box_counts = {cls_name: 0 for cls_name in self.classes}\n            for img_path in images_paths:\n                labels = YoloImage(image_path=img_path).get_labels()\n                for label in labels:\n                    cls_name = self.classes[label[\"class\"]]\n                    box_counts[cls_name] += 1\n\n            for cls_name, box_count in box_counts.items():\n                print(f\"  + {cls_name}: {box_count} boxes\")\n\n        print(\"- Subsets:\")\n        total_file_count = 0\n        for folder_path in [\n            self.train_folder,\n            self.valid_folder,\n            self.test_folder,\n        ]:\n            if folder_path.exists():\n                file_count = len(list_files(str(folder_path / \"images\")))\n                print(f\"  + {folder_path.name}: {file_count} images\")\n                total_file_count += file_count\n        print(\"- Total images:\", total_file_count)\n\n    @classmethod\n    def _combine_classes(cls, datasets_paths):\n        \"\"\"\n        Combine classes from multiple datasets.\n\n        Returns:\n            datasets_paths (list(str)): Paths to the dataset folders.\n\n        Returns:\n            classes (list(str)): Combined list of class names.\n        \"\"\"\n        classes = set()\n\n        for path in datasets_paths:\n            new_classes = cls.get_classes(str(Path(path) / \"data.yaml\"))\n            classes.update(new_classes)\n\n        classes = list(classes)\n        classes.sort()\n\n        return classes\n\n    @classmethod\n    def _get_reindex_dict(cls, source_classes, target_classes):\n        \"\"\"\n        Get the reindexing dictionary for mapping classes from source to target.\n\n        Returns:\n            source_classes (list(str)): Source class names.\n            target_classes (list(str)): Target class names.\n\n        Returns:\n            reindex_dict (dict): Reindexing dictionary.\n        \"\"\"\n        reindex_dict = dict()\n        for i, class_name in enumerate(source_classes):\n            if class_name in target_classes:\n                reindex_dict[i] = target_classes.index(class_name)\n\n        return reindex_dict\n\n    @classmethod\n    def _create_simple_yaml_file(cls, dataset_path, classes):\n        \"\"\"\n        Create a simple YAML file containing dataset information.\n\n        Returns:\n            dataset_path (str): Path to the dataset folder.\n            classes (list[str]): List of class names.\n        \"\"\"\n        data = {\n            \"train\": \"train\",\n            \"val\": \"valid\",\n            \"test\": \"test\",\n            \"names\": classes,\n        }\n\n        yaml_path = Path(dataset_path) / \"data.yaml\"\n        with open(str(yaml_path), \"w\") as f:\n            yaml.dump(data, f)\n\n    @classmethod\n    def merge_datasets(cls, datasets_paths, merged_dataset_path):\n        \"\"\"\n        Merge multiple datasets into one.\n\n        Returns:\n            datasets_paths (list[str]): Paths to the dataset folders to be merged.\n            merged_dataset_path (str): Path to the merged dataset folder.\n        \"\"\"\n        merged_dataset_path = Path(merged_dataset_path)\n        merged_classes = cls._combine_classes(datasets_paths)\n        print(\"Input datasets:\")\n        for path in datasets_paths:\n            dataset = cls(path)\n            dataset.summary()\n            classes = dataset.classes\n            reindex_dict = cls._get_reindex_dict(classes, merged_classes)\n\n            for subset_path in [\n                dataset.train_folder,\n                dataset.valid_folder,\n                dataset.test_folder,\n            ]:\n                if subset_path.exists():\n                    target_subset_path = merged_dataset_path / subset_path.name\n                    create_folder(target_subset_path / \"images\")\n                    create_folder(target_subset_path / \"labels\")\n                    images_paths = list_files(str(subset_path / \"images\"))\n                    for image_path in images_paths:\n                        yolo_image = YoloImage(image_path)\n                        yolo_image.copy_to(\n                            target_subset_path,\n                            dataset.name + \"_\",\n                            reindex_dict,\n                        )\n\n        cls._create_simple_yaml_file(str(merged_dataset_path), merged_classes)\n\n        print(\"Merged dataset:\")\n        dataset = cls(str(merged_dataset_path))\n        dataset.summary()\n\n    def split(self, splitted_dataset_path, ratios=[0.9]):\n        \"\"\"\n        Split the dataset into train, validation, and test subsets.\n\n        Returns:\n            splitted_dataset_path (str): Path to the folder where the splitted dataset will be saved.\n            ratios (list[float]): Ratios for train, validation, and test subsets. Default is [0.9].\n        \"\"\"\n        self.summary()\n\n        images_paths = list()\n        for folder_path in [\n            self.train_folder,\n            self.valid_folder,\n            self.test_folder,\n        ]:\n            if folder_path.exists():\n                images_paths += list_files(str(folder_path / \"images\"))\n\n        random.shuffle(images_paths)\n\n        total_paths = len(images_paths)\n\n        train_count = int(total_paths * ratios[0])\n        train_paths = images_paths[:train_count]\n\n        if len(ratios) == 1:\n            valid_paths = images_paths[train_count:]\n            test_paths = list()\n        else:\n            valid_count = int(total_paths * ratios[1])\n            valid_paths = images_paths[train_count : train_count + valid_count]\n            test_paths = images_paths[train_count + valid_count :]\n\n        splitted_dataset_path = Path(splitted_dataset_path)\n\n        subsets = [\n            (\"train\", train_paths),\n            (\"valid\", valid_paths),\n            (\"test\", test_paths),\n        ]\n        for subset_name, paths in subsets:\n            for path in paths:\n                yolo_image = YoloImage(path)\n                old_subset_name = Path(path).parent.parent.name\n                target_folder_path = splitted_dataset_path / subset_name\n                create_folder(target_folder_path / \"images\")\n                create_folder(target_folder_path / \"labels\")\n                yolo_image.copy_to(\n                    target_folder_path, f\"{self.name}_{old_subset_name}_\"\n                )\n\n        self._create_simple_yaml_file(str(splitted_dataset_path), self.classes)\n        YoloDataset(str(splitted_dataset_path)).summary()\n\n    def rename_classes(self, renamed_dataset_path, renaming_dict):\n        \"\"\"\n        Rename classes in the dataset.\n\n        Returns:\n            renamed_dataset_path (str): Path to the folder where the renamed dataset will be saved.\n            renaming_dict (dict): Dictionary mapping original class names to new class names.\n                To remove classes, set the classes' values to None.\n        \"\"\"\n\n        self.summary()\n\n        target_classes = [\n            class_name\n            for class_name in renaming_dict.values()\n            if class_name is not None\n        ]\n\n        for class_name in self.classes:\n            if class_name not in renaming_dict.keys():\n                target_classes.append(class_name)\n\n        target_classes = list(set(target_classes))\n        target_classes.sort()\n\n        print(\"Classes after renaming:\", target_classes)\n\n        reindex_dict = dict()\n\n        for i, class_name in enumerate(self.classes):\n            renamed_class = class_name\n            if class_name in renaming_dict:\n                renamed_class = renaming_dict[class_name]\n\n            if renamed_class is None:\n                reindex_dict[i] = None\n            else:\n                reindex_dict[i] = target_classes.index(renamed_class)\n\n        renamed_dataset_path = Path(renamed_dataset_path)\n        for subset_name, folder_path in [\n            (\"train\", self.train_folder),\n            (\"valid\", self.valid_folder),\n            (\"test\", self.test_folder),\n        ]:\n            if folder_path.exists():\n                images_paths = list_files(folder_path / \"images\")\n                for path in images_paths:\n                    yolo_image = YoloImage(path)\n                    target_folder_path = renamed_dataset_path / subset_name\n                    create_folder(target_folder_path / \"images\")\n                    create_folder(target_folder_path / \"labels\")\n                    yolo_image.copy_to(\n                        target_folder_path, f\"{self.name}_\", reindex_dict\n                    )\n\n        self._create_simple_yaml_file(\n            str(renamed_dataset_path), target_classes\n        )\n        YoloDataset(str(renamed_dataset_path)).summary()\n\n    def show_sample(self, figsize=(10, 10)):\n        \"\"\"\n        Show a sample of annotated images from the dataset.\n\n        Returns:\n            figsize (tuple(int, int)): Size of the figure (width, height) in inches.\n        \"\"\"\n\n        images_paths = list()\n        for folder_path in [\n            self.train_folder,\n            self.valid_folder,\n            self.test_folder,\n        ]:\n            if folder_path.exists():\n                images_paths += list_files(str(folder_path / \"images\"))\n\n        random.shuffle(images_paths)\n\n        labels_dict = {\n            i: class_name for i, class_name in enumerate(self.classes)\n        }\n        annotated_images = list()\n        if len(images_paths) &gt; 9:\n            for i in range(3):\n                annotated_images.append(list())\n                for j in range(3):\n                    yolo_image = YoloImage(\n                        images_paths[i * 3 + j], labels_dict, self.task\n                    )\n                    annotated_images[i].append(\n                        yolo_image.get_annotated_image()\n                    )\n        else:\n            total_images = min(3, len(images_paths))\n            for i in range(total_images):\n                yolo_image = YoloImage(images_paths[i], labels_dict, self.task)\n                annotated_images.append(yolo_image.get_annotated_image())\n\n        concatenated_images = concatenate_images(annotated_images)\n\n        show_image(concatenated_images, figsize=figsize)\n\n    def number_filenames(self, numbered_dataset_path):\n        \"\"\"\n        Number filenames of images in the dataset.\n\n        Returns:\n            numbered_dataset_path (str): Path to the folder where the numbered dataset will be saved.\n        \"\"\"\n        self.summary()\n\n        total_images = 0\n\n        for folder_path in [\n            self.train_folder,\n            self.valid_folder,\n            self.test_folder,\n        ]:\n            if folder_path.exists():\n                total_images += len(list_files(str(folder_path / \"images\")))\n\n        n_digits = len(str(total_images))\n        i = 0\n\n        subsets = [\n            (\"train\", self.train_folder),\n            (\"valid\", self.valid_folder),\n            (\"test\", self.test_folder),\n        ]\n        numbered_dataset_path = Path(numbered_dataset_path)\n        for subset_name, folder_path in subsets:\n            if folder_path.exists():\n                images_paths = list_files(str(folder_path / \"images\"))\n                for path in images_paths:\n                    yolo_image = YoloImage(path)\n                    target_folder_path = numbered_dataset_path / subset_name\n                    create_folder(target_folder_path / \"images\")\n                    create_folder(target_folder_path / \"labels\")\n                    yolo_image.copy_to(\n                        target_folder_path, target_stem=str(i).zfill(n_digits)\n                    )\n                    i += 1\n\n        self._create_simple_yaml_file(str(numbered_dataset_path), self.classes)\n        YoloDataset(str(numbered_dataset_path)).summary()\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.__init__","title":"<code>__init__(dataset_path, task='detect')</code>","text":"<p>Initialize a YoloDataset object.</p> <p>Returns:</p> Name Type Description <code>dataset_path</code> <code>str</code> <p>Path to the dataset folder.</p> <code>task</code> <code>str</code> <p>. Dataset use case. Default is \"detect\".         Possible values: \"detect\", \"pose\".</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def __init__(self, dataset_path, task=\"detect\"):\n    \"\"\"\n    Initialize a YoloDataset object.\n\n    Returns:\n        dataset_path (str): Path to the dataset folder.\n        task (str): . Dataset use case. Default is \"detect\".\n                    Possible values: \"detect\", \"pose\".\n    \"\"\"\n    self.dataset_path = Path(dataset_path)\n    self.name = self.dataset_path.name\n    self.train_folder = self.dataset_path / \"train\"\n    self.valid_folder = self.dataset_path / \"valid\"\n    self.test_folder = self.dataset_path / \"test\"\n    self.classes = self.get_classes(str(self.dataset_path / \"data.yaml\"))\n    if task not in TASKS:\n        raise ValueError(\"Unexpected task. Please provide one of:\", TASKS)\n    self.task = task\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.get_classes","title":"<code>get_classes(yaml_path)</code>  <code>classmethod</code>","text":"<p>Retrieve classes from a YAML file.</p> <p>Returns:</p> Name Type Description <code>yaml_path</code> <code>str</code> <p>Path to the YAML file containing class names.</p> <p>Returns:</p> Name Type Description <code>names</code> <code>list(str)</code> <p>List of class names.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>@classmethod\ndef get_classes(cls, yaml_path):\n    \"\"\"\n    Retrieve classes from a YAML file.\n\n    Returns:\n        yaml_path (str): Path to the YAML file containing class names.\n\n    Returns:\n        names (list(str)): List of class names.\n    \"\"\"\n    with open(yaml_path, \"r\") as file:\n        data = yaml.safe_load(file)\n    return data[\"names\"]\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.merge_datasets","title":"<code>merge_datasets(datasets_paths, merged_dataset_path)</code>  <code>classmethod</code>","text":"<p>Merge multiple datasets into one.</p> <p>Returns:</p> Name Type Description <code>datasets_paths</code> <code>list[str]</code> <p>Paths to the dataset folders to be merged.</p> <code>merged_dataset_path</code> <code>str</code> <p>Path to the merged dataset folder.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>@classmethod\ndef merge_datasets(cls, datasets_paths, merged_dataset_path):\n    \"\"\"\n    Merge multiple datasets into one.\n\n    Returns:\n        datasets_paths (list[str]): Paths to the dataset folders to be merged.\n        merged_dataset_path (str): Path to the merged dataset folder.\n    \"\"\"\n    merged_dataset_path = Path(merged_dataset_path)\n    merged_classes = cls._combine_classes(datasets_paths)\n    print(\"Input datasets:\")\n    for path in datasets_paths:\n        dataset = cls(path)\n        dataset.summary()\n        classes = dataset.classes\n        reindex_dict = cls._get_reindex_dict(classes, merged_classes)\n\n        for subset_path in [\n            dataset.train_folder,\n            dataset.valid_folder,\n            dataset.test_folder,\n        ]:\n            if subset_path.exists():\n                target_subset_path = merged_dataset_path / subset_path.name\n                create_folder(target_subset_path / \"images\")\n                create_folder(target_subset_path / \"labels\")\n                images_paths = list_files(str(subset_path / \"images\"))\n                for image_path in images_paths:\n                    yolo_image = YoloImage(image_path)\n                    yolo_image.copy_to(\n                        target_subset_path,\n                        dataset.name + \"_\",\n                        reindex_dict,\n                    )\n\n    cls._create_simple_yaml_file(str(merged_dataset_path), merged_classes)\n\n    print(\"Merged dataset:\")\n    dataset = cls(str(merged_dataset_path))\n    dataset.summary()\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.number_filenames","title":"<code>number_filenames(numbered_dataset_path)</code>","text":"<p>Number filenames of images in the dataset.</p> <p>Returns:</p> Name Type Description <code>numbered_dataset_path</code> <code>str</code> <p>Path to the folder where the numbered dataset will be saved.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def number_filenames(self, numbered_dataset_path):\n    \"\"\"\n    Number filenames of images in the dataset.\n\n    Returns:\n        numbered_dataset_path (str): Path to the folder where the numbered dataset will be saved.\n    \"\"\"\n    self.summary()\n\n    total_images = 0\n\n    for folder_path in [\n        self.train_folder,\n        self.valid_folder,\n        self.test_folder,\n    ]:\n        if folder_path.exists():\n            total_images += len(list_files(str(folder_path / \"images\")))\n\n    n_digits = len(str(total_images))\n    i = 0\n\n    subsets = [\n        (\"train\", self.train_folder),\n        (\"valid\", self.valid_folder),\n        (\"test\", self.test_folder),\n    ]\n    numbered_dataset_path = Path(numbered_dataset_path)\n    for subset_name, folder_path in subsets:\n        if folder_path.exists():\n            images_paths = list_files(str(folder_path / \"images\"))\n            for path in images_paths:\n                yolo_image = YoloImage(path)\n                target_folder_path = numbered_dataset_path / subset_name\n                create_folder(target_folder_path / \"images\")\n                create_folder(target_folder_path / \"labels\")\n                yolo_image.copy_to(\n                    target_folder_path, target_stem=str(i).zfill(n_digits)\n                )\n                i += 1\n\n    self._create_simple_yaml_file(str(numbered_dataset_path), self.classes)\n    YoloDataset(str(numbered_dataset_path)).summary()\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.rename_classes","title":"<code>rename_classes(renamed_dataset_path, renaming_dict)</code>","text":"<p>Rename classes in the dataset.</p> <p>Returns:</p> Name Type Description <code>renamed_dataset_path</code> <code>str</code> <p>Path to the folder where the renamed dataset will be saved.</p> <code>renaming_dict</code> <code>dict</code> <p>Dictionary mapping original class names to new class names. To remove classes, set the classes' values to None.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def rename_classes(self, renamed_dataset_path, renaming_dict):\n    \"\"\"\n    Rename classes in the dataset.\n\n    Returns:\n        renamed_dataset_path (str): Path to the folder where the renamed dataset will be saved.\n        renaming_dict (dict): Dictionary mapping original class names to new class names.\n            To remove classes, set the classes' values to None.\n    \"\"\"\n\n    self.summary()\n\n    target_classes = [\n        class_name\n        for class_name in renaming_dict.values()\n        if class_name is not None\n    ]\n\n    for class_name in self.classes:\n        if class_name not in renaming_dict.keys():\n            target_classes.append(class_name)\n\n    target_classes = list(set(target_classes))\n    target_classes.sort()\n\n    print(\"Classes after renaming:\", target_classes)\n\n    reindex_dict = dict()\n\n    for i, class_name in enumerate(self.classes):\n        renamed_class = class_name\n        if class_name in renaming_dict:\n            renamed_class = renaming_dict[class_name]\n\n        if renamed_class is None:\n            reindex_dict[i] = None\n        else:\n            reindex_dict[i] = target_classes.index(renamed_class)\n\n    renamed_dataset_path = Path(renamed_dataset_path)\n    for subset_name, folder_path in [\n        (\"train\", self.train_folder),\n        (\"valid\", self.valid_folder),\n        (\"test\", self.test_folder),\n    ]:\n        if folder_path.exists():\n            images_paths = list_files(folder_path / \"images\")\n            for path in images_paths:\n                yolo_image = YoloImage(path)\n                target_folder_path = renamed_dataset_path / subset_name\n                create_folder(target_folder_path / \"images\")\n                create_folder(target_folder_path / \"labels\")\n                yolo_image.copy_to(\n                    target_folder_path, f\"{self.name}_\", reindex_dict\n                )\n\n    self._create_simple_yaml_file(\n        str(renamed_dataset_path), target_classes\n    )\n    YoloDataset(str(renamed_dataset_path)).summary()\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.show_sample","title":"<code>show_sample(figsize=(10, 10))</code>","text":"<p>Show a sample of annotated images from the dataset.</p> <p>Returns:</p> Name Type Description <code>figsize</code> <code>tuple(int, int)</code> <p>Size of the figure (width, height) in inches.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def show_sample(self, figsize=(10, 10)):\n    \"\"\"\n    Show a sample of annotated images from the dataset.\n\n    Returns:\n        figsize (tuple(int, int)): Size of the figure (width, height) in inches.\n    \"\"\"\n\n    images_paths = list()\n    for folder_path in [\n        self.train_folder,\n        self.valid_folder,\n        self.test_folder,\n    ]:\n        if folder_path.exists():\n            images_paths += list_files(str(folder_path / \"images\"))\n\n    random.shuffle(images_paths)\n\n    labels_dict = {\n        i: class_name for i, class_name in enumerate(self.classes)\n    }\n    annotated_images = list()\n    if len(images_paths) &gt; 9:\n        for i in range(3):\n            annotated_images.append(list())\n            for j in range(3):\n                yolo_image = YoloImage(\n                    images_paths[i * 3 + j], labels_dict, self.task\n                )\n                annotated_images[i].append(\n                    yolo_image.get_annotated_image()\n                )\n    else:\n        total_images = min(3, len(images_paths))\n        for i in range(total_images):\n            yolo_image = YoloImage(images_paths[i], labels_dict, self.task)\n            annotated_images.append(yolo_image.get_annotated_image())\n\n    concatenated_images = concatenate_images(annotated_images)\n\n    show_image(concatenated_images, figsize=figsize)\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.split","title":"<code>split(splitted_dataset_path, ratios=[0.9])</code>","text":"<p>Split the dataset into train, validation, and test subsets.</p> <p>Returns:</p> Name Type Description <code>splitted_dataset_path</code> <code>str</code> <p>Path to the folder where the splitted dataset will be saved.</p> <code>ratios</code> <code>list[float]</code> <p>Ratios for train, validation, and test subsets. Default is [0.9].</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def split(self, splitted_dataset_path, ratios=[0.9]):\n    \"\"\"\n    Split the dataset into train, validation, and test subsets.\n\n    Returns:\n        splitted_dataset_path (str): Path to the folder where the splitted dataset will be saved.\n        ratios (list[float]): Ratios for train, validation, and test subsets. Default is [0.9].\n    \"\"\"\n    self.summary()\n\n    images_paths = list()\n    for folder_path in [\n        self.train_folder,\n        self.valid_folder,\n        self.test_folder,\n    ]:\n        if folder_path.exists():\n            images_paths += list_files(str(folder_path / \"images\"))\n\n    random.shuffle(images_paths)\n\n    total_paths = len(images_paths)\n\n    train_count = int(total_paths * ratios[0])\n    train_paths = images_paths[:train_count]\n\n    if len(ratios) == 1:\n        valid_paths = images_paths[train_count:]\n        test_paths = list()\n    else:\n        valid_count = int(total_paths * ratios[1])\n        valid_paths = images_paths[train_count : train_count + valid_count]\n        test_paths = images_paths[train_count + valid_count :]\n\n    splitted_dataset_path = Path(splitted_dataset_path)\n\n    subsets = [\n        (\"train\", train_paths),\n        (\"valid\", valid_paths),\n        (\"test\", test_paths),\n    ]\n    for subset_name, paths in subsets:\n        for path in paths:\n            yolo_image = YoloImage(path)\n            old_subset_name = Path(path).parent.parent.name\n            target_folder_path = splitted_dataset_path / subset_name\n            create_folder(target_folder_path / \"images\")\n            create_folder(target_folder_path / \"labels\")\n            yolo_image.copy_to(\n                target_folder_path, f\"{self.name}_{old_subset_name}_\"\n            )\n\n    self._create_simple_yaml_file(str(splitted_dataset_path), self.classes)\n    YoloDataset(str(splitted_dataset_path)).summary()\n</code></pre>"},{"location":"cv/dataset_utils/#kano.dataset_utils.YoloDataset.summary","title":"<code>summary(count_box=False)</code>","text":"<p>Print summary information about the dataset.</p> Source code in <code>kano\\dataset_utils.py</code> <pre><code>def summary(self, count_box=False):\n    \"\"\"\n    Print summary information about the dataset.\n    \"\"\"\n    print(f\"Summary dataset {self.dataset_path.name}:\")\n    print(\"- Classes: \", self.classes)\n\n    if count_box:\n        print(\n            \"  *Note: the box counting can take a long time depend on dataset size, please wait...\"\n        )\n        images_paths = list()\n        for folder_path in [\n            self.train_folder,\n            self.valid_folder,\n            self.test_folder,\n        ]:\n            if folder_path.exists():\n                images_paths += list_files(str(folder_path / \"images\"))\n\n        box_counts = {cls_name: 0 for cls_name in self.classes}\n        for img_path in images_paths:\n            labels = YoloImage(image_path=img_path).get_labels()\n            for label in labels:\n                cls_name = self.classes[label[\"class\"]]\n                box_counts[cls_name] += 1\n\n        for cls_name, box_count in box_counts.items():\n            print(f\"  + {cls_name}: {box_count} boxes\")\n\n    print(\"- Subsets:\")\n    total_file_count = 0\n    for folder_path in [\n        self.train_folder,\n        self.valid_folder,\n        self.test_folder,\n    ]:\n        if folder_path.exists():\n            file_count = len(list_files(str(folder_path / \"images\")))\n            print(f\"  + {folder_path.name}: {file_count} images\")\n            total_file_count += file_count\n    print(\"- Total images:\", total_file_count)\n</code></pre>"},{"location":"cv/detect_utils/","title":"Object Detection utilites","text":"<p>Kano aims to support visualization and extract bounding boxes without the need to handle various box formats, such as xyxy, xywh, or scaled xywh:</p> <ul> <li><code>xywh2xyxy</code>: convert box with xywh format (x_center, y_center, width, height - which is model input/output format) to xyxy format(x_min, y_min, x_max, y_max - which used to draw boxes).</li> <li><code>extract_bbox_area</code>: get cropped box image from the image</li> <li><code>draw_bbox</code>: draw bounding box on the image.</li> </ul>"},{"location":"cv/detect_utils/#kano.detect_utils.xywh2xyxy","title":"<code>kano.detect_utils.xywh2xyxy(xywh)</code>","text":"<p>Converts bounding box coordinates from (x_center, y_center, width, height) format to (x_min, y_min, x_max, y_max) format.</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>np.array) with shape (4,</code> <p>A tuple containing (x_center, y_center, width, height) of the bounding box.</p> required <p>Returns:</p> Name Type Description <code>xyxy</code> <code>tuple(int)</code> <p>xyxy location of the bounding box.</p> Source code in <code>kano\\detect_utils.py</code> <pre><code>def xywh2xyxy(xywh):\n    \"\"\"\n    Converts bounding box coordinates from (x_center, y_center, width, height) format to (x_min, y_min, x_max, y_max) format.\n\n    Args:\n        xywh (np.array) with shape (4,): A tuple containing (x_center, y_center, width, height) of the bounding box.\n\n    Returns:\n        xyxy (tuple(int)): xyxy location of the bounding box.\n    \"\"\"\n\n    x_center, y_center, bbox_width, bbox_height = xywh\n    x_min = int(x_center - bbox_width / 2)\n    y_min = int(y_center - bbox_height / 2)\n    x_max = int(x_center + bbox_width / 2)\n    y_max = int(y_center + bbox_height / 2)\n\n    return x_min, y_min, x_max, y_max\n</code></pre>"},{"location":"cv/detect_utils/#kano.detect_utils.extract_bbox_area","title":"<code>kano.detect_utils.extract_bbox_area(image, bbox)</code>","text":"<p>Return cropped image from the given bounding box area</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>np.array) with shape (H, W, 3</code> <p>image to extract the box</p> required <code>bbox</code> <code>np.array) with shape (4,</code> <p>xyxy location of the box</p> required <p>Returns:</p> Name Type Description <code>cropped_image</code> <code>array</code> <p>with shape (new_H, new_W, 3) based on bbox</p> Source code in <code>kano\\detect_utils.py</code> <pre><code>def extract_bbox_area(image, bbox):\n    \"\"\"\n    Return cropped image from the given bounding box area\n\n    Args:\n        image (np.array) with shape (H, W, 3): image to extract the box\n        bbox (np.array) with shape (4,): xyxy location of the box\n\n    Returns:\n        cropped_image (np.array): with shape (new_H, new_W, 3) based on bbox\n    \"\"\"\n\n    (left, top), (right, bottom) = bbox[:2], bbox[2:]\n    return image.copy()[top:bottom, left:right]\n</code></pre>"},{"location":"cv/detect_utils/#kano.detect_utils.draw_bbox","title":"<code>kano.detect_utils.draw_bbox(image, bbox, bbox_type='xyxy', bbox_color=(0, 0, 255), label=None)</code>","text":"<p>Draws a bounding box on the image and optionally draws a multi-line label.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray or str</code> <p>The image on which the bounding box will be drawn.</p> required <code>bbox</code> <code>list or tuple or ndarray</code> <p>The bounding box coordinates. If it's a list, it should be in the format specified by bbox_type.</p> required <code>bbox_type</code> <code>str</code> <p>Type of bounding box coordinates. Should be either \"xyxy\" or \"xywh\" or \"s_xywh\".</p> <code>'xyxy'</code> <code>bbox_color</code> <code>tuple</code> <p>Color of the bounding box in BGR format.</p> <code>(0, 0, 255)</code> <code>label</code> <code>str</code> <p>Label to be displayed alongside the bounding box. Supports multiple lines with '/n' separating lines.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Image with the bounding box and label drawn.</p> Source code in <code>kano\\detect_utils.py</code> <pre><code>def draw_bbox(\n    image: Union[np.ndarray, str],\n    bbox: Union[List[float], Tuple[float, ...], np.ndarray],\n    bbox_type: str = \"xyxy\",\n    bbox_color: Tuple[int, int, int] = (0, 0, 255),\n    label: Optional[str] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Draws a bounding box on the image and optionally draws a multi-line label.\n\n    Args:\n        image (np.ndarray or str): The image on which the bounding box will be drawn.\n        bbox (list or tuple or np.ndarray): The bounding box coordinates. If it's a list, it should be in the format specified by bbox_type.\n        bbox_type (str): Type of bounding box coordinates. Should be either \"xyxy\" or \"xywh\" or \"s_xywh\".\n        bbox_color (tuple): Color of the bounding box in BGR format.\n        label (str, optional): Label to be displayed alongside the bounding box. Supports multiple lines with '/n' separating lines.\n\n    Returns:\n        np.ndarray: Image with the bounding box and label drawn.\n    \"\"\"\n    if isinstance(image, str):\n        temp_image = cv2.imread(image)\n    else:\n        temp_image = image.copy()\n\n    image_height, image_width = temp_image.shape[:2]\n\n    if isinstance(bbox, (list, tuple)):\n        temp_bbox = np.array(bbox)\n    temp_bbox = temp_bbox.copy()\n    if \"s_\" in bbox_type:\n        temp_bbox *= np.array(\n            [image_width, image_height, image_width, image_height]\n        )\n\n    temp_bbox = temp_bbox.astype(np.int64)\n\n    if \"xyxy\" in bbox_type:\n        x_min, y_min, x_max, y_max = temp_bbox\n    elif \"xywh\" in bbox_type:\n        x_min, y_min, x_max, y_max = xywh2xyxy(temp_bbox)\n    else:\n        raise ValueError(\"Invalid bounding box type\")\n\n    cv2.rectangle(temp_image, (x_min, y_min), (x_max, y_max), bbox_color, 2)\n\n    if label is not None:\n        font = cv2.FONT_HERSHEY_SIMPLEX\n        font_scale, thickness, pad = get_font_config(image_height)\n\n        label_lines = label.split(\"\\n\")\n        (text_width, text_height), _ = cv2.getTextSize(\n            \"sample\", font, font_scale, thickness\n        )\n        y_offset = y_min - (text_height + pad) * (len(label_lines) - 1)\n\n        for line in label_lines:\n            (text_width, text_height), _ = cv2.getTextSize(\n                line, font, font_scale, thickness\n            )\n\n            background_position = (x_min, y_offset)\n            background_end_position = (\n                x_min + text_width,\n                y_offset - text_height - pad,\n            )\n            cv2.rectangle(\n                temp_image,\n                background_position,\n                background_end_position,\n                bbox_color,\n                -1,\n            )\n            cv2.putText(\n                temp_image,\n                line,\n                (x_min, y_offset - pad // 2),\n                font,\n                font_scale,\n                (255, 255, 255),\n                thickness,\n            )\n\n            y_offset += text_height + pad\n\n    return temp_image\n</code></pre>"},{"location":"lab/","title":"Real-Time Simulation Utilities","text":"<p>Developing computer vision applications often requires working with real-time camera feeds or RTSP streams, rather than just a set of pre-recorded videos. Kano offers tools to:</p> <ul> <li>Measure pipeline FPS (frames per second).</li> <li>Simulate real-time camera streams from videos.</li> <li>Generate fake detection results for testing object detection tasks.</li> </ul>"},{"location":"lab/#track-fps-of-your-pipeline-with-fpscounter-class","title":"Track FPS of your pipeline with FPSCounter Class","text":"<p>The <code>FPSCounter</code> class tracks the number of frames processed over time and computes the FPS. It also provides an option to print FPS at specified intervals and ensure that the FPS does not exceed a target value.</p> <pre><code>import time\n\nfrom kano.lab.profiler import FPSCounter\n\n# Initialize FPSCounter with a 1-second print cycle\nfps_counter = FPSCounter(fps_print_cycle=1, prefix_fps_print=\"App\")\n\n# Simulate frame processing\nfor i in range(100):\n    fps_counter.update()\n    time.sleep(0.01)  # Simulating 100 frames per second (10ms per frame)\n</code></pre> <p>Result:</p> <pre><code>App FPS: 100\nApp FPS: 100\nApp FPS: 100\n...\n</code></pre>"},{"location":"lab/#get-cpu-percent-and-ram-usage-of-your-python-process","title":"Get CPU percent and RAM usage of your python process","text":"<p>The <code>ResourceProfiler</code> class monitors the system's CPU and RAM usage for a given process (default is the current process) and logs the data to a CSV file. You can also print the resource usage at specified intervals.</p> <pre><code>import time\n\nfrom kano.lab.profiler import ResourceProfiler\n\n# Initialize ResourceProfiler to monitor CPU and RAM usage every 2 seconds\nprofiler = ResourceProfiler(interval_seconds=2, csv_path=\"resource_usage.csv\")\n\n# Start monitoring and printing data every 2 seconds\nwhile True:\n    profiler.update()\n    time.sleep(1)\n</code></pre> <p>Result:</p> <pre><code>PID: 12345 - CPU Usage: 12.3% - total RAM: 200.15 MiB\nPID: 12345 - CPU Usage: 14.1% - total RAM: 202.35 MiB\n...\n</code></pre>"},{"location":"lab/#simulate-real-time-camera-streams-with-videostreamer","title":"Simulate real-time camera streams with <code>VideoStreamer</code>","text":"<p>The <code>VideoStreamer</code> class streams video from a source (file or camera) and retrieves frames in real-time, ensuring that the current frame is always processed without delay. Unlike <code>cv2.VideoCapture</code>, which might introduce a delay while waiting for the next frame in the stream, <code>VideoStreamer</code> fetches the frame at the current time, making it ideal for real-time processing.</p> <pre><code>from kano.lab.source_reader import VideoStreamer\n\n\nvideo_streamer = VideoStreamer(\"video.mp4\")\nwhile True:\n    frame = video_streamer.get_latest_frame()\n    print(frame.shape)  # Process the frame\n</code></pre>"},{"location":"lab/#generate-animated-object-detection-results-with-fakedetect","title":"Generate animated object detection results with <code>FakeDetect</code>","text":"<p>The <code>FakeDetect</code> class provides a utility to simulate smooth transitions between two bounding boxes over a specified duration. It is particularly useful for testing and visualizing object detection systems, where such transitions can mimic real-world movement or animations.</p> <pre><code>import time\n\nimport cv2\nimport numpy as np\nfrom kano.lab import FakeDetect, Box\nfrom kano.detect_utils import draw_bbox\n\n\nfake_detect = FakeDetect(\n    begin_box=Box(width=200, height=400, point=[300, 500]),\n    end_box=Box(width=400, height=200, point=[1500, 500]),\n    duration=4,\n)\nfake_detect.start(time.time())\n\ncanvas = np.zeros((1080, 1920, 3), dtype=np.uint8)\n\nwhile True:\n    canvas[:] = 0\n    xyxy = fake_detect.move(time.time())\n    if xyxy is not None:\n        canvas = draw_bbox(canvas, xyxy, bbox_color=(0, 255, 0))\n\n    cv2.imshow(\"1920x1080\", canvas)\n\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\ncv2.destroyAllWindows()\n</code></pre> <p>Result:</p> <p></p>"},{"location":"lab/#generate-and-control-animated-object-detection-sequences-with-detectgen","title":"Generate and Control Animated Object Detection Sequences with <code>DetectGen</code>","text":"<p>The <code>DetectGen</code> module manages and generates a sequence of fake detections for simulation or testing object detection tasks. It allows for smooth transitions between bounding boxes over specified durations and supports looping options such as:</p> <ul> <li>NoLoop: Plays once and stops.</li> <li>Reversed: Reverses the sequence after completion.</li> <li>Replay: Repeats the sequence from the beginning.</li> </ul> <pre><code>import time\n\nimport cv2\nimport numpy as np\nfrom kano.lab import Box, LoopType, DetectGen\nfrom kano.detect_utils import draw_bbox\n\ndetect_gen = DetectGen(\n    boxes=[\n        Box(200, 200, [200, 200]),\n        Box(400, 400, [960, 600]),\n        Box(200, 200, [1720, 200]),\n    ],\n    durations=[2, 1],\n    loop_type=LoopType.Reversed,\n)\ndetect_gen.start(time.time())\ncanvas = np.zeros((1080, 1920, 3), dtype=np.uint8)\nwhile True:\n    canvas[:] = 0\n    xyxy = detect_gen.gen_xyxy(time.time())\n\n    if xyxy is not None:\n        canvas = draw_bbox(canvas, xyxy, bbox_color=(0, 255, 0))\n\n    cv2.imshow(\"1920x1080\", canvas)\n\n    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n        break\n\ncv2.destroyAllWindows()\n</code></pre> <p>Result:</p> <p></p>"},{"location":"lab/fake_detection/","title":"Real-time Fake Detection","text":"<p>Kano provides classes for simulating and visualizing object detection results, including smooth transitions between bounding boxes. The following classes are included:</p> <ul> <li><code>FakeDetect</code>: Simulates smooth transitions between two bounding boxes over a specified duration, ideal for testing object detection systems.</li> <li><code>DetectGen</code>: Manages and generates a sequence of fake detections with looping options like NoLoop, Reversed, and Replay for flexible simulation and testing.</li> </ul>"},{"location":"lab/fake_detection/#kano.lab.box_gen.fake_detect.FakeDetect","title":"<code>kano.lab.box_gen.fake_detect.FakeDetect</code>","text":"<p>Simulates an animated transition between two boxes over a specified duration.</p> Source code in <code>kano\\lab\\box_gen\\fake_detect.py</code> <pre><code>class FakeDetect:\n    \"\"\"\n    Simulates an animated transition between two boxes over a specified duration.\n    \"\"\"\n\n    def __init__(\n        self,\n        begin_box: Box,\n        end_box: Box,\n        duration: float,\n        start_after: float = 0,\n        from_bottom: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the FakeDetect instance.\n\n        Args:\n            begin_box (Box): The starting box of the transition.\n            end_box (Box): The ending box of the transition.\n            duration (float): The duration of the transition in seconds.\n            start_after (float): The delay before starting the transition. Default is 0.\n            from_bottom (bool): Whether to use bottom-aligned coordinates. Default is False.\n        \"\"\"\n        self.begin_box = begin_box\n        self.end_box = end_box\n        self.duration = duration\n        self.start_after = start_after\n        self.from_bottom = from_bottom\n        self.start_time: float = None\n\n    def reverse(self) -&gt; None:\n        \"\"\"\n        Reverses the transition by swapping the starting and ending boxes.\n        \"\"\"\n        self.begin_box, self.end_box = self.end_box, self.begin_box\n\n    def start(self, current_time: float) -&gt; None:\n        \"\"\"\n        Starts the transition at the specified current time.\n\n        Args:\n            current_time (float): The current time to start the transition.\n        \"\"\"\n        self.start_time = current_time\n\n    def _get_current_box(self, elapsed_time: float) -&gt; Box:\n        \"\"\"\n        Computes the intermediate box based on the elapsed time.\n\n        Args:\n            elapsed_time (float): The elapsed time since the transition started.\n\n        Returns:\n            Box: The interpolated box at the current state of the transition.\n        \"\"\"\n        new_width = solve_equation(\n            elapsed_time,\n            self.duration,\n            self.begin_box.width,\n            self.end_box.width,\n        )\n        new_height = solve_equation(\n            elapsed_time,\n            self.duration,\n            self.begin_box.height,\n            self.end_box.height,\n        )\n        new_point = solve_equation(\n            elapsed_time,\n            self.duration,\n            self.begin_box.point,\n            self.end_box.point,\n        )\n        return Box(\n            width=int(new_width),\n            height=int(new_height),\n            point=new_point,\n        )\n\n    def move(self, current_time: float) -&gt; np.ndarray:\n        \"\"\"\n        Computes the current box's coordinates in (xmin, ymin, xmax, ymax) format.\n\n        Args:\n            current_time (float): The current time used to compute the box's state.\n\n        Returns:\n            np.ndarray: The current box's coordinates, or None if the transition has not started or is finished.\n\n        Raises:\n            ValueError: If the start time is not set.\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\n                \"Start time is not set. Call start() method first.\"\n            )\n\n        elapsed_time = current_time - self.start_time\n        if (\n            elapsed_time &lt; self.start_after\n            or elapsed_time &gt; self.duration + self.start_after\n        ):\n            return None\n\n        return self._get_current_box(elapsed_time).get_xyxy(self.from_bottom)\n\n    def is_end(self, current_time: float) -&gt; bool:\n        \"\"\"\n        Determines whether the transition has finished.\n\n        Args:\n            current_time (float): The current time to check against the transition's end time.\n\n        Returns:\n            bool: True if the transition has ended, False otherwise.\n\n        Raises:\n            ValueError: If the start time is not set.\n        \"\"\"\n        if self.start_time is None:\n            raise ValueError(\n                \"Start time is not set. Call start() method first.\"\n            )\n\n        elapsed_time = current_time - self.start_time\n        return elapsed_time &gt; self.duration + self.start_after\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.fake_detect.FakeDetect.__init__","title":"<code>__init__(begin_box, end_box, duration, start_after=0, from_bottom=False)</code>","text":"<p>Initializes the FakeDetect instance.</p> <p>Parameters:</p> Name Type Description Default <code>begin_box</code> <code>Box</code> <p>The starting box of the transition.</p> required <code>end_box</code> <code>Box</code> <p>The ending box of the transition.</p> required <code>duration</code> <code>float</code> <p>The duration of the transition in seconds.</p> required <code>start_after</code> <code>float</code> <p>The delay before starting the transition. Default is 0.</p> <code>0</code> <code>from_bottom</code> <code>bool</code> <p>Whether to use bottom-aligned coordinates. Default is False.</p> <code>False</code> Source code in <code>kano\\lab\\box_gen\\fake_detect.py</code> <pre><code>def __init__(\n    self,\n    begin_box: Box,\n    end_box: Box,\n    duration: float,\n    start_after: float = 0,\n    from_bottom: bool = False,\n) -&gt; None:\n    \"\"\"\n    Initializes the FakeDetect instance.\n\n    Args:\n        begin_box (Box): The starting box of the transition.\n        end_box (Box): The ending box of the transition.\n        duration (float): The duration of the transition in seconds.\n        start_after (float): The delay before starting the transition. Default is 0.\n        from_bottom (bool): Whether to use bottom-aligned coordinates. Default is False.\n    \"\"\"\n    self.begin_box = begin_box\n    self.end_box = end_box\n    self.duration = duration\n    self.start_after = start_after\n    self.from_bottom = from_bottom\n    self.start_time: float = None\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.fake_detect.FakeDetect.is_end","title":"<code>is_end(current_time)</code>","text":"<p>Determines whether the transition has finished.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current time to check against the transition's end time.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the transition has ended, False otherwise.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the start time is not set.</p> Source code in <code>kano\\lab\\box_gen\\fake_detect.py</code> <pre><code>def is_end(self, current_time: float) -&gt; bool:\n    \"\"\"\n    Determines whether the transition has finished.\n\n    Args:\n        current_time (float): The current time to check against the transition's end time.\n\n    Returns:\n        bool: True if the transition has ended, False otherwise.\n\n    Raises:\n        ValueError: If the start time is not set.\n    \"\"\"\n    if self.start_time is None:\n        raise ValueError(\n            \"Start time is not set. Call start() method first.\"\n        )\n\n    elapsed_time = current_time - self.start_time\n    return elapsed_time &gt; self.duration + self.start_after\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.fake_detect.FakeDetect.move","title":"<code>move(current_time)</code>","text":"<p>Computes the current box's coordinates in (xmin, ymin, xmax, ymax) format.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current time used to compute the box's state.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The current box's coordinates, or None if the transition has not started or is finished.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the start time is not set.</p> Source code in <code>kano\\lab\\box_gen\\fake_detect.py</code> <pre><code>def move(self, current_time: float) -&gt; np.ndarray:\n    \"\"\"\n    Computes the current box's coordinates in (xmin, ymin, xmax, ymax) format.\n\n    Args:\n        current_time (float): The current time used to compute the box's state.\n\n    Returns:\n        np.ndarray: The current box's coordinates, or None if the transition has not started or is finished.\n\n    Raises:\n        ValueError: If the start time is not set.\n    \"\"\"\n    if self.start_time is None:\n        raise ValueError(\n            \"Start time is not set. Call start() method first.\"\n        )\n\n    elapsed_time = current_time - self.start_time\n    if (\n        elapsed_time &lt; self.start_after\n        or elapsed_time &gt; self.duration + self.start_after\n    ):\n        return None\n\n    return self._get_current_box(elapsed_time).get_xyxy(self.from_bottom)\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.fake_detect.FakeDetect.reverse","title":"<code>reverse()</code>","text":"<p>Reverses the transition by swapping the starting and ending boxes.</p> Source code in <code>kano\\lab\\box_gen\\fake_detect.py</code> <pre><code>def reverse(self) -&gt; None:\n    \"\"\"\n    Reverses the transition by swapping the starting and ending boxes.\n    \"\"\"\n    self.begin_box, self.end_box = self.end_box, self.begin_box\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.fake_detect.FakeDetect.start","title":"<code>start(current_time)</code>","text":"<p>Starts the transition at the specified current time.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current time to start the transition.</p> required Source code in <code>kano\\lab\\box_gen\\fake_detect.py</code> <pre><code>def start(self, current_time: float) -&gt; None:\n    \"\"\"\n    Starts the transition at the specified current time.\n\n    Args:\n        current_time (float): The current time to start the transition.\n    \"\"\"\n    self.start_time = current_time\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen","title":"<code>kano.lab.box_gen.detect_gen.DetectGen</code>","text":"<p>Class to manage and generate a sequence of fake detections for animation or simulation purposes.</p> Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>class DetectGen:\n    \"\"\"\n    Class to manage and generate a sequence of fake detections for animation or simulation purposes.\n    \"\"\"\n\n    def __init__(\n        self,\n        boxes: List[Box],\n        durations: List[float],\n        start_after: float = 0,\n        from_bottom: bool = False,\n        loop_type: LoopType = LoopType.NoLoop,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the DetectGen object with the given boxes and durations.\n\n        Args:\n            boxes (List[Box]): A list of Box objects representing the sequence.\n            durations (List[float]): Durations for transitions between boxes.\n            start_after (float): Initial delay before starting the sequence. Default is 0.\n            from_bottom (bool): Whether to use bottom-aligned coordinates. Default is False.\n            loop_type (LoopType): Type of looping for the sequence. Default is NoLoop.\n\n        Raises:\n            InvalidEnumValueError: If the loop_type is not a valid LoopType.\n        \"\"\"\n        if loop_type not in LoopType.__members__.values():\n            raise InvalidEnumValueError(LoopType, loop_type)\n\n        self.loop_type = loop_type\n        self.fake_detects = self.get_sequence_detect(\n            boxes, durations, start_after, from_bottom\n        )\n        self.start_time: float = None\n        self.curr_i: int = 0\n        self.stop: bool = False\n\n    def start(self, current_time: float) -&gt; None:\n        \"\"\"\n        Starts the sequence at the specified current time.\n\n        Args:\n            current_time (float): The current time to start the sequence.\n        \"\"\"\n        self.start_time = current_time\n        self.fake_detects[0].start(current_time)\n\n    def _update_i(self, current_time: float) -&gt; None:\n        \"\"\"\n        Updates the current index of the detection sequence based on the current time.\n\n        Args:\n            current_time (float): The current time used to update the sequence.\n        \"\"\"\n        if not self.fake_detects[self.curr_i].is_end(current_time):\n            return\n\n        if self.curr_i &lt; len(self.fake_detects) - 1:\n            self.start_time += self.fake_detects[self.curr_i].duration\n            self.curr_i += 1\n            self.fake_detects[self.curr_i].start(self.start_time)\n            return\n\n        if self.loop_type == LoopType.NoLoop:\n            self.stop = True\n            return\n\n        if self.loop_type == LoopType.Reversed:\n            self.reverse_sequence()\n            return\n\n        if self.loop_type == LoopType.Replay:\n            self.replay_sequence()\n            return\n\n    def reverse_sequence(self) -&gt; None:\n        \"\"\"\n        Reverses the sequence of detections.\n        \"\"\"\n        self.fake_detects[0].start_after = 0\n        self.start_time += self.fake_detects[self.curr_i].duration\n        for fake_det in self.fake_detects:\n            fake_det.reverse()\n        self.fake_detects = self.fake_detects[::-1]\n        self.curr_i = 0\n        self.fake_detects[self.curr_i].start(self.start_time)\n\n    def replay_sequence(self) -&gt; None:\n        \"\"\"\n        Replays the detection sequence from the beginning.\n        \"\"\"\n        self.fake_detects[0].start_after = 0\n        self.start_time += self.fake_detects[self.curr_i].duration\n        self.curr_i = 0\n        self.fake_detects[self.curr_i].start(self.start_time)\n\n    def gen_xyxy(self, current_time: float) -&gt; bool:\n        \"\"\"\n        Generates the current (xmin, ymin, xmax, ymax) coordinates for the sequence.\n\n        Args:\n            current_time (float): The current time for coordinate generation.\n\n        Returns:\n            bool: True if the sequence has ended, otherwise False.\n        \"\"\"\n        self._update_i(current_time)\n        if self.stop:\n            return True\n        return self.fake_detects[self.curr_i].move(current_time)\n\n    def get_sequence_detect(\n        self,\n        boxes: List[Box],\n        durations: List[float],\n        start_after: float = 0,\n        from_bottom: bool = False,\n    ) -&gt; List[FakeDetect]:\n        \"\"\"\n        Creates a sequence of FakeDetect objects based on the provided boxes and durations.\n\n        Args:\n            boxes (List[Box]): A list of Box objects representing the sequence.\n            durations (List[float]): A list of durations for transitions between boxes.\n            start_after (float): Initial delay before starting the sequence. Default is 0.\n            from_bottom (bool): Whether to use bottom-aligned coordinates. Default is False.\n\n        Returns:\n            List[FakeDetect]: A list of FakeDetect objects for the sequence.\n\n        Raises:\n            ValueError: If there are fewer than 2 boxes or if the number of durations is invalid.\n        \"\"\"\n        if len(boxes) &lt; 2:\n            raise ValueError(\"Need at least 2 boxes\")\n\n        if len(boxes) != len(durations) + 1:\n            raise ValueError(\n                f\"The number of boxes must be exactly one more than the number of durations. \"\n                f\"Got {len(boxes)} boxes and {len(durations)} durations.\"\n            )\n\n        fake_detects = []\n        for i in range(len(boxes) - 1):\n            fake_detects.append(\n                FakeDetect(\n                    begin_box=boxes[i],\n                    end_box=boxes[i + 1],\n                    duration=durations[i],\n                    start_after=start_after,\n                    from_bottom=from_bottom,\n                )\n            )\n        return fake_detects\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen.__init__","title":"<code>__init__(boxes, durations, start_after=0, from_bottom=False, loop_type=LoopType.NoLoop)</code>","text":"<p>Initializes the DetectGen object with the given boxes and durations.</p> <p>Parameters:</p> Name Type Description Default <code>boxes</code> <code>List[Box]</code> <p>A list of Box objects representing the sequence.</p> required <code>durations</code> <code>List[float]</code> <p>Durations for transitions between boxes.</p> required <code>start_after</code> <code>float</code> <p>Initial delay before starting the sequence. Default is 0.</p> <code>0</code> <code>from_bottom</code> <code>bool</code> <p>Whether to use bottom-aligned coordinates. Default is False.</p> <code>False</code> <code>loop_type</code> <code>LoopType</code> <p>Type of looping for the sequence. Default is NoLoop.</p> <code>NoLoop</code> <p>Raises:</p> Type Description <code>InvalidEnumValueError</code> <p>If the loop_type is not a valid LoopType.</p> Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>def __init__(\n    self,\n    boxes: List[Box],\n    durations: List[float],\n    start_after: float = 0,\n    from_bottom: bool = False,\n    loop_type: LoopType = LoopType.NoLoop,\n) -&gt; None:\n    \"\"\"\n    Initializes the DetectGen object with the given boxes and durations.\n\n    Args:\n        boxes (List[Box]): A list of Box objects representing the sequence.\n        durations (List[float]): Durations for transitions between boxes.\n        start_after (float): Initial delay before starting the sequence. Default is 0.\n        from_bottom (bool): Whether to use bottom-aligned coordinates. Default is False.\n        loop_type (LoopType): Type of looping for the sequence. Default is NoLoop.\n\n    Raises:\n        InvalidEnumValueError: If the loop_type is not a valid LoopType.\n    \"\"\"\n    if loop_type not in LoopType.__members__.values():\n        raise InvalidEnumValueError(LoopType, loop_type)\n\n    self.loop_type = loop_type\n    self.fake_detects = self.get_sequence_detect(\n        boxes, durations, start_after, from_bottom\n    )\n    self.start_time: float = None\n    self.curr_i: int = 0\n    self.stop: bool = False\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen.gen_xyxy","title":"<code>gen_xyxy(current_time)</code>","text":"<p>Generates the current (xmin, ymin, xmax, ymax) coordinates for the sequence.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current time for coordinate generation.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the sequence has ended, otherwise False.</p> Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>def gen_xyxy(self, current_time: float) -&gt; bool:\n    \"\"\"\n    Generates the current (xmin, ymin, xmax, ymax) coordinates for the sequence.\n\n    Args:\n        current_time (float): The current time for coordinate generation.\n\n    Returns:\n        bool: True if the sequence has ended, otherwise False.\n    \"\"\"\n    self._update_i(current_time)\n    if self.stop:\n        return True\n    return self.fake_detects[self.curr_i].move(current_time)\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen.get_sequence_detect","title":"<code>get_sequence_detect(boxes, durations, start_after=0, from_bottom=False)</code>","text":"<p>Creates a sequence of FakeDetect objects based on the provided boxes and durations.</p> <p>Parameters:</p> Name Type Description Default <code>boxes</code> <code>List[Box]</code> <p>A list of Box objects representing the sequence.</p> required <code>durations</code> <code>List[float]</code> <p>A list of durations for transitions between boxes.</p> required <code>start_after</code> <code>float</code> <p>Initial delay before starting the sequence. Default is 0.</p> <code>0</code> <code>from_bottom</code> <code>bool</code> <p>Whether to use bottom-aligned coordinates. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[FakeDetect]</code> <p>List[FakeDetect]: A list of FakeDetect objects for the sequence.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are fewer than 2 boxes or if the number of durations is invalid.</p> Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>def get_sequence_detect(\n    self,\n    boxes: List[Box],\n    durations: List[float],\n    start_after: float = 0,\n    from_bottom: bool = False,\n) -&gt; List[FakeDetect]:\n    \"\"\"\n    Creates a sequence of FakeDetect objects based on the provided boxes and durations.\n\n    Args:\n        boxes (List[Box]): A list of Box objects representing the sequence.\n        durations (List[float]): A list of durations for transitions between boxes.\n        start_after (float): Initial delay before starting the sequence. Default is 0.\n        from_bottom (bool): Whether to use bottom-aligned coordinates. Default is False.\n\n    Returns:\n        List[FakeDetect]: A list of FakeDetect objects for the sequence.\n\n    Raises:\n        ValueError: If there are fewer than 2 boxes or if the number of durations is invalid.\n    \"\"\"\n    if len(boxes) &lt; 2:\n        raise ValueError(\"Need at least 2 boxes\")\n\n    if len(boxes) != len(durations) + 1:\n        raise ValueError(\n            f\"The number of boxes must be exactly one more than the number of durations. \"\n            f\"Got {len(boxes)} boxes and {len(durations)} durations.\"\n        )\n\n    fake_detects = []\n    for i in range(len(boxes) - 1):\n        fake_detects.append(\n            FakeDetect(\n                begin_box=boxes[i],\n                end_box=boxes[i + 1],\n                duration=durations[i],\n                start_after=start_after,\n                from_bottom=from_bottom,\n            )\n        )\n    return fake_detects\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen.replay_sequence","title":"<code>replay_sequence()</code>","text":"<p>Replays the detection sequence from the beginning.</p> Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>def replay_sequence(self) -&gt; None:\n    \"\"\"\n    Replays the detection sequence from the beginning.\n    \"\"\"\n    self.fake_detects[0].start_after = 0\n    self.start_time += self.fake_detects[self.curr_i].duration\n    self.curr_i = 0\n    self.fake_detects[self.curr_i].start(self.start_time)\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen.reverse_sequence","title":"<code>reverse_sequence()</code>","text":"<p>Reverses the sequence of detections.</p> Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>def reverse_sequence(self) -&gt; None:\n    \"\"\"\n    Reverses the sequence of detections.\n    \"\"\"\n    self.fake_detects[0].start_after = 0\n    self.start_time += self.fake_detects[self.curr_i].duration\n    for fake_det in self.fake_detects:\n        fake_det.reverse()\n    self.fake_detects = self.fake_detects[::-1]\n    self.curr_i = 0\n    self.fake_detects[self.curr_i].start(self.start_time)\n</code></pre>"},{"location":"lab/fake_detection/#kano.lab.box_gen.detect_gen.DetectGen.start","title":"<code>start(current_time)</code>","text":"<p>Starts the sequence at the specified current time.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current time to start the sequence.</p> required Source code in <code>kano\\lab\\box_gen\\detect_gen.py</code> <pre><code>def start(self, current_time: float) -&gt; None:\n    \"\"\"\n    Starts the sequence at the specified current time.\n\n    Args:\n        current_time (float): The current time to start the sequence.\n    \"\"\"\n    self.start_time = current_time\n    self.fake_detects[0].start(current_time)\n</code></pre>"},{"location":"lab/profiler/","title":"Resource Profiling and FPS Tracking","text":"<p>Kano provides classes for monitoring system resource usage (CPU and RAM) and tracking frames per second (FPS). The following classes are included:</p> <ul> <li>FPSCounter: A class that tracks frames per second (FPS) for a given application.</li> <li>ResourceProfiler: A class that monitors system resource usage (CPU and RAM) at regular intervals and optionally logs the data to a CSV file.</li> <li>FPSProfiler: A subclass of <code>ResourceProfiler</code> that also tracks FPS and logs it along with CPU and RAM usage.</li> </ul>"},{"location":"lab/profiler/#kano.lab.profiler.FPSCounter","title":"<code>kano.lab.profiler.FPSCounter</code>","text":"Source code in <code>kano\\lab\\profiler.py</code> <pre><code>class FPSCounter:\n    def __init__(\n        self, start_when_init=True, fps_print_cycle=None, prefix_fps_print=\"\"\n    ):\n        \"\"\"\n        Initializes the FPSCounter instance.\n\n        Args:\n            start_when_init (bool): Whether to start counting FPS immediately upon initialization.\n            fps_print_cycle (float or None): The interval (in seconds) at which FPS will be printed.\n            prefix_fps_print (str): A prefix string to include in the FPS print statement.\n        \"\"\"\n        self.start_time = None\n        self.total_frames = 0\n        self.last_print_time = None\n        self.fps_print_cycle = fps_print_cycle\n        self.prefix_fps_print = prefix_fps_print\n        if start_when_init:\n            self.start()\n\n    def start(self):\n        \"\"\"\n        Resets the FPS counter and starts the time tracking.\n\n        Initializes the start time and sets the total frame count to 0.\n        \"\"\"\n        self.start_time = time.time()\n        self.last_print_time = self.start_time\n        self.total_frames = 0\n\n    def update(self):\n        \"\"\"\n        Updates the FPS counter by incrementing the frame count and optionally printing the FPS.\n\n        If the frame count exceeds 1,000,000, the counter is reset.\n        If `fps_print_cycle` is set, the FPS is printed at the specified interval.\n        \"\"\"\n        if self.total_frames &gt; 1_000_000:\n            self.start()\n        else:\n            self.total_frames += 1\n\n        if self.fps_print_cycle is not None:\n            elapsed_time = time.time() - self.last_print_time\n            if elapsed_time &gt;= self.fps_print_cycle:\n                print(f\"{self.prefix_fps_print} FPS: {int(self.get_fps())}\")\n                self.start()\n\n    def get_fps(self):\n        \"\"\"\n        Get the current FPS (frames per second).\n\n        Calculates FPS as the total number of frames divided by the elapsed time.\n\n        Returns:\n            float: The calculated FPS, or 0 if the counter has not started.\n        \"\"\"\n        if self.start_time is None:\n            return 0\n        elapsed_time = time.time() - self.start_time\n        if elapsed_time == 0:\n            return 0\n        fps = self.total_frames / elapsed_time\n        return fps\n\n    def keep_target_fps(self, target_fps):\n        \"\"\"\n        Ensure the FPS stays below or at the target FPS by adjusting the sleep time.\n\n        Args:\n            target_fps (float): The target FPS to maintain.\n        \"\"\"\n        current_fps = self.get_fps()\n        if current_fps &gt; target_fps:\n            sleep_time = self.total_frames / target_fps - (\n                time.time() - self.start_time\n            )\n            if sleep_time &gt; 0:\n                time.sleep(sleep_time)\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSCounter.__init__","title":"<code>__init__(start_when_init=True, fps_print_cycle=None, prefix_fps_print='')</code>","text":"<p>Initializes the FPSCounter instance.</p> <p>Parameters:</p> Name Type Description Default <code>start_when_init</code> <code>bool</code> <p>Whether to start counting FPS immediately upon initialization.</p> <code>True</code> <code>fps_print_cycle</code> <code>float or None</code> <p>The interval (in seconds) at which FPS will be printed.</p> <code>None</code> <code>prefix_fps_print</code> <code>str</code> <p>A prefix string to include in the FPS print statement.</p> <code>''</code> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def __init__(\n    self, start_when_init=True, fps_print_cycle=None, prefix_fps_print=\"\"\n):\n    \"\"\"\n    Initializes the FPSCounter instance.\n\n    Args:\n        start_when_init (bool): Whether to start counting FPS immediately upon initialization.\n        fps_print_cycle (float or None): The interval (in seconds) at which FPS will be printed.\n        prefix_fps_print (str): A prefix string to include in the FPS print statement.\n    \"\"\"\n    self.start_time = None\n    self.total_frames = 0\n    self.last_print_time = None\n    self.fps_print_cycle = fps_print_cycle\n    self.prefix_fps_print = prefix_fps_print\n    if start_when_init:\n        self.start()\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSCounter.get_fps","title":"<code>get_fps()</code>","text":"<p>Get the current FPS (frames per second).</p> <p>Calculates FPS as the total number of frames divided by the elapsed time.</p> <p>Returns:</p> Name Type Description <code>float</code> <p>The calculated FPS, or 0 if the counter has not started.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def get_fps(self):\n    \"\"\"\n    Get the current FPS (frames per second).\n\n    Calculates FPS as the total number of frames divided by the elapsed time.\n\n    Returns:\n        float: The calculated FPS, or 0 if the counter has not started.\n    \"\"\"\n    if self.start_time is None:\n        return 0\n    elapsed_time = time.time() - self.start_time\n    if elapsed_time == 0:\n        return 0\n    fps = self.total_frames / elapsed_time\n    return fps\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSCounter.keep_target_fps","title":"<code>keep_target_fps(target_fps)</code>","text":"<p>Ensure the FPS stays below or at the target FPS by adjusting the sleep time.</p> <p>Parameters:</p> Name Type Description Default <code>target_fps</code> <code>float</code> <p>The target FPS to maintain.</p> required Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def keep_target_fps(self, target_fps):\n    \"\"\"\n    Ensure the FPS stays below or at the target FPS by adjusting the sleep time.\n\n    Args:\n        target_fps (float): The target FPS to maintain.\n    \"\"\"\n    current_fps = self.get_fps()\n    if current_fps &gt; target_fps:\n        sleep_time = self.total_frames / target_fps - (\n            time.time() - self.start_time\n        )\n        if sleep_time &gt; 0:\n            time.sleep(sleep_time)\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSCounter.start","title":"<code>start()</code>","text":"<p>Resets the FPS counter and starts the time tracking.</p> <p>Initializes the start time and sets the total frame count to 0.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def start(self):\n    \"\"\"\n    Resets the FPS counter and starts the time tracking.\n\n    Initializes the start time and sets the total frame count to 0.\n    \"\"\"\n    self.start_time = time.time()\n    self.last_print_time = self.start_time\n    self.total_frames = 0\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSCounter.update","title":"<code>update()</code>","text":"<p>Updates the FPS counter by incrementing the frame count and optionally printing the FPS.</p> <p>If the frame count exceeds 1,000,000, the counter is reset. If <code>fps_print_cycle</code> is set, the FPS is printed at the specified interval.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def update(self):\n    \"\"\"\n    Updates the FPS counter by incrementing the frame count and optionally printing the FPS.\n\n    If the frame count exceeds 1,000,000, the counter is reset.\n    If `fps_print_cycle` is set, the FPS is printed at the specified interval.\n    \"\"\"\n    if self.total_frames &gt; 1_000_000:\n        self.start()\n    else:\n        self.total_frames += 1\n\n    if self.fps_print_cycle is not None:\n        elapsed_time = time.time() - self.last_print_time\n        if elapsed_time &gt;= self.fps_print_cycle:\n            print(f\"{self.prefix_fps_print} FPS: {int(self.get_fps())}\")\n            self.start()\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.ResourceProfiler","title":"<code>kano.lab.profiler.ResourceProfiler</code>","text":"Source code in <code>kano\\lab\\profiler.py</code> <pre><code>class ResourceProfiler:\n    def __init__(\n        self, interval_seconds, pid=None, csv_path=None, csv_minutes=5\n    ):\n        \"\"\"\n        Initializes the ResourceProfiler instance.\n\n        Args:\n            interval_seconds (float): The interval in seconds between each resource update.\n            pid (int or None): The process ID to monitor, or None to monitor the current process.\n            csv_path (str or None): Path to a CSV file to save resource data, or None to skip saving.\n            csv_minutes (int): The number of minutes of data to retain in the CSV file.\n        \"\"\"\n        self.interval_seconds = interval_seconds\n        self.last_update_time = time.time()\n        if pid:\n            self.current_process = psutil.Process(pid)\n            self.pid = pid\n        else:\n            self.current_process = psutil.Process()\n            self.pid = os.getpid()\n        self.csv_path = csv_path\n        self.csv_minutes = csv_minutes\n        self.time_format = \"%Y-%m-%d %H:%M:%S\"\n\n    def update_csv(self, current_time, cpu_percent, ram_mib):\n        \"\"\"\n        Update the CSV file with the current resource usage.\n\n        Args:\n            current_time (float): The current timestamp.\n            cpu_percent (float): The current CPU usage as a percentage.\n            ram_mib (float): The current RAM usage in MiB.\n        \"\"\"\n        if os.path.isfile(self.csv_path):\n            df = pd.read_csv(self.csv_path)\n            df = df[df[\"time\"] &gt; current_time - self.csv_minutes * 60]\n        else:\n            df = pd.DataFrame(columns=[\"time\", \"cpu_percent\", \"ram_mib\"])\n\n        new_line = {\n            \"time\": current_time,\n            \"cpu_percent\": cpu_percent,\n            \"ram_mib\": ram_mib,\n        }\n\n        df.loc[len(df)] = new_line\n        df.to_csv(self.csv_path, index=False, header=True)\n\n    def get_current_info(self):\n        \"\"\"\n        Get the current process resource usage (CPU and RAM).\n\n        Returns:\n            tuple: A tuple containing the current timestamp, CPU usage percentage, and RAM usage in MiB.\n        \"\"\"\n        current_time = time.time()\n        cpu_percent = self.current_process.cpu_percent()\n        ram_mib = self.current_process.memory_info().rss / 1024**2\n        return current_time, cpu_percent, ram_mib\n\n    def update(self):\n        \"\"\"\n        Update the resource usage information and optionally print it.\n\n        If the interval has elapsed, the current CPU and RAM usage will be printed.\n        If a CSV path is specified, the data will be written to the CSV file.\n        \"\"\"\n        current_time, cpu_percent, ram_mib = self.get_current_info()\n        if current_time - self.last_update_time &gt;= self.interval_seconds:\n            print(\n                f\"PID: {self.pid} - CPU Usage: {cpu_percent}% - total RAM: {ram_mib:.2f} MiB\"\n            )\n            self.last_update_time = current_time\n        if self.csv_path:\n            self.update_csv(current_time, cpu_percent, ram_mib)\n\n    def _profiling(self):\n        \"\"\"\n        Continuously profiles the resources at the specified interval.\n\n        This method runs in a separate thread and continuously updates the resource usage.\n        \"\"\"\n        while True:\n            current_time, cpu_percent, ram_mib = self.get_current_info()\n            if current_time - self.last_update_time &gt;= self.interval_seconds:\n                print(\n                    f\"PID: {self.pid} - CPU Usage: {cpu_percent}% - total RAM: {ram_mib:.2f} MiB\"\n                )\n                self.last_update_time = current_time\n            if self.csv_path:\n                self.update_csv(current_time, cpu_percent, ram_mib)\n            time.sleep(self.interval_seconds)\n\n    def start_profiling_thread(self):\n        \"\"\"\n        Start a separate thread for continuous resource profiling.\n\n        The thread runs the `_profiling` method to collect and display resource usage.\n        \"\"\"\n        thread = threading.Thread(target=self._profiling)\n        thread.start()\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.ResourceProfiler.__init__","title":"<code>__init__(interval_seconds, pid=None, csv_path=None, csv_minutes=5)</code>","text":"<p>Initializes the ResourceProfiler instance.</p> <p>Parameters:</p> Name Type Description Default <code>interval_seconds</code> <code>float</code> <p>The interval in seconds between each resource update.</p> required <code>pid</code> <code>int or None</code> <p>The process ID to monitor, or None to monitor the current process.</p> <code>None</code> <code>csv_path</code> <code>str or None</code> <p>Path to a CSV file to save resource data, or None to skip saving.</p> <code>None</code> <code>csv_minutes</code> <code>int</code> <p>The number of minutes of data to retain in the CSV file.</p> <code>5</code> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def __init__(\n    self, interval_seconds, pid=None, csv_path=None, csv_minutes=5\n):\n    \"\"\"\n    Initializes the ResourceProfiler instance.\n\n    Args:\n        interval_seconds (float): The interval in seconds between each resource update.\n        pid (int or None): The process ID to monitor, or None to monitor the current process.\n        csv_path (str or None): Path to a CSV file to save resource data, or None to skip saving.\n        csv_minutes (int): The number of minutes of data to retain in the CSV file.\n    \"\"\"\n    self.interval_seconds = interval_seconds\n    self.last_update_time = time.time()\n    if pid:\n        self.current_process = psutil.Process(pid)\n        self.pid = pid\n    else:\n        self.current_process = psutil.Process()\n        self.pid = os.getpid()\n    self.csv_path = csv_path\n    self.csv_minutes = csv_minutes\n    self.time_format = \"%Y-%m-%d %H:%M:%S\"\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.ResourceProfiler.get_current_info","title":"<code>get_current_info()</code>","text":"<p>Get the current process resource usage (CPU and RAM).</p> <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the current timestamp, CPU usage percentage, and RAM usage in MiB.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def get_current_info(self):\n    \"\"\"\n    Get the current process resource usage (CPU and RAM).\n\n    Returns:\n        tuple: A tuple containing the current timestamp, CPU usage percentage, and RAM usage in MiB.\n    \"\"\"\n    current_time = time.time()\n    cpu_percent = self.current_process.cpu_percent()\n    ram_mib = self.current_process.memory_info().rss / 1024**2\n    return current_time, cpu_percent, ram_mib\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.ResourceProfiler.start_profiling_thread","title":"<code>start_profiling_thread()</code>","text":"<p>Start a separate thread for continuous resource profiling.</p> <p>The thread runs the <code>_profiling</code> method to collect and display resource usage.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def start_profiling_thread(self):\n    \"\"\"\n    Start a separate thread for continuous resource profiling.\n\n    The thread runs the `_profiling` method to collect and display resource usage.\n    \"\"\"\n    thread = threading.Thread(target=self._profiling)\n    thread.start()\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.ResourceProfiler.update","title":"<code>update()</code>","text":"<p>Update the resource usage information and optionally print it.</p> <p>If the interval has elapsed, the current CPU and RAM usage will be printed. If a CSV path is specified, the data will be written to the CSV file.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def update(self):\n    \"\"\"\n    Update the resource usage information and optionally print it.\n\n    If the interval has elapsed, the current CPU and RAM usage will be printed.\n    If a CSV path is specified, the data will be written to the CSV file.\n    \"\"\"\n    current_time, cpu_percent, ram_mib = self.get_current_info()\n    if current_time - self.last_update_time &gt;= self.interval_seconds:\n        print(\n            f\"PID: {self.pid} - CPU Usage: {cpu_percent}% - total RAM: {ram_mib:.2f} MiB\"\n        )\n        self.last_update_time = current_time\n    if self.csv_path:\n        self.update_csv(current_time, cpu_percent, ram_mib)\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.ResourceProfiler.update_csv","title":"<code>update_csv(current_time, cpu_percent, ram_mib)</code>","text":"<p>Update the CSV file with the current resource usage.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current timestamp.</p> required <code>cpu_percent</code> <code>float</code> <p>The current CPU usage as a percentage.</p> required <code>ram_mib</code> <code>float</code> <p>The current RAM usage in MiB.</p> required Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def update_csv(self, current_time, cpu_percent, ram_mib):\n    \"\"\"\n    Update the CSV file with the current resource usage.\n\n    Args:\n        current_time (float): The current timestamp.\n        cpu_percent (float): The current CPU usage as a percentage.\n        ram_mib (float): The current RAM usage in MiB.\n    \"\"\"\n    if os.path.isfile(self.csv_path):\n        df = pd.read_csv(self.csv_path)\n        df = df[df[\"time\"] &gt; current_time - self.csv_minutes * 60]\n    else:\n        df = pd.DataFrame(columns=[\"time\", \"cpu_percent\", \"ram_mib\"])\n\n    new_line = {\n        \"time\": current_time,\n        \"cpu_percent\": cpu_percent,\n        \"ram_mib\": ram_mib,\n    }\n\n    df.loc[len(df)] = new_line\n    df.to_csv(self.csv_path, index=False, header=True)\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSProfiler","title":"<code>kano.lab.profiler.FPSProfiler</code>","text":"<p>               Bases: <code>ResourceProfiler</code></p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>class FPSProfiler(ResourceProfiler):\n    def __init__(\n        self,\n        interval_seconds,\n        pid=None,\n        csv_path=None,\n        csv_minutes=5,\n        target_fps=None,\n    ):\n        \"\"\"\n        Initializes the FPSProfiler instance, extending ResourceProfiler to track FPS.\n\n        Args:\n            interval_seconds (float): The interval in seconds between each resource update.\n            pid (int or None): The process ID to monitor, or None to monitor the current process.\n            csv_path (str or None): Path to a CSV file to save resource and FPS data.\n            csv_minutes (int): The number of minutes of data to retain in the CSV file.\n            target_fps (float or None): The target FPS to maintain.\n        \"\"\"\n        super().__init__(interval_seconds, pid, csv_path, csv_minutes)\n        self.fps_counter = FPSCounter()\n        self.target_fps = target_fps\n\n    def update_csv(self, current_time, cpu_percent, ram_mib, fps):\n        \"\"\"\n        Update the CSV file with the current resource usage and FPS.\n\n        Args:\n            current_time (float): The current timestamp.\n            cpu_percent (float): The current CPU usage as a percentage.\n            ram_mib (float): The current RAM usage in MiB.\n            fps (int): The current frames per second.\n        \"\"\"\n        if os.path.isfile(self.csv_path):\n            df = pd.read_csv(self.csv_path)\n            df = df[df[\"time\"] &gt; current_time - self.csv_minutes * 60]\n        else:\n            df = pd.DataFrame(\n                columns=[\"time\", \"cpu_percent\", \"ram_mib\", \"fps\"]\n            )\n        new_line = {\n            \"time\": current_time,\n            \"cpu_percent\": cpu_percent,\n            \"ram_mib\": ram_mib,\n            \"fps\": fps,\n        }\n        df.loc[len(df)] = new_line\n        df.to_csv(self.csv_path, index=False, header=True)\n\n    def get_current_info(self):\n        \"\"\"\n        Get the current resource usage and FPS.\n\n        Returns:\n            tuple: A tuple containing the current timestamp, CPU usage percentage, RAM usage in MiB, and FPS.\n        \"\"\"\n        current_time, cpu_percent, ram_mib = super().get_current_info()\n        self.fps_counter.update()\n        fps = int(self.fps_counter.get_fps())\n        return current_time, cpu_percent, ram_mib, fps\n\n    def update(self):\n        \"\"\"\n        Update the resource usage and FPS information, printing and saving to CSV if applicable.\n\n        If the interval has elapsed, the current CPU, RAM, and FPS usage will be printed.\n        If a CSV path is specified, the data will be written to the CSV file.\n        If a target FPS is defined, attempts to maintain the target FPS.\n\n        Returns:\n            tuple: A tuple containing CPU usage percentage, RAM usage in MiB, and FPS.\n        \"\"\"\n        current_time, cpu_percent, ram_mib, fps = self.get_current_info()\n        if current_time - self.last_update_time &gt;= self.interval_seconds:\n            print(\n                f\"PID: {self.pid} - CPU Usage: {cpu_percent}% - total RAM: {ram_mib:.2f} MiB - FPS: {fps}\"\n            )\n            self.last_update_time = current_time\n        if self.csv_path:\n            self.update_csv(current_time, cpu_percent, ram_mib, fps)\n        if self.target_fps:\n            self.fps_counter.keep_target_fps(self.target_fps)\n        return cpu_percent, ram_mib, fps\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSProfiler.__init__","title":"<code>__init__(interval_seconds, pid=None, csv_path=None, csv_minutes=5, target_fps=None)</code>","text":"<p>Initializes the FPSProfiler instance, extending ResourceProfiler to track FPS.</p> <p>Parameters:</p> Name Type Description Default <code>interval_seconds</code> <code>float</code> <p>The interval in seconds between each resource update.</p> required <code>pid</code> <code>int or None</code> <p>The process ID to monitor, or None to monitor the current process.</p> <code>None</code> <code>csv_path</code> <code>str or None</code> <p>Path to a CSV file to save resource and FPS data.</p> <code>None</code> <code>csv_minutes</code> <code>int</code> <p>The number of minutes of data to retain in the CSV file.</p> <code>5</code> <code>target_fps</code> <code>float or None</code> <p>The target FPS to maintain.</p> <code>None</code> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def __init__(\n    self,\n    interval_seconds,\n    pid=None,\n    csv_path=None,\n    csv_minutes=5,\n    target_fps=None,\n):\n    \"\"\"\n    Initializes the FPSProfiler instance, extending ResourceProfiler to track FPS.\n\n    Args:\n        interval_seconds (float): The interval in seconds between each resource update.\n        pid (int or None): The process ID to monitor, or None to monitor the current process.\n        csv_path (str or None): Path to a CSV file to save resource and FPS data.\n        csv_minutes (int): The number of minutes of data to retain in the CSV file.\n        target_fps (float or None): The target FPS to maintain.\n    \"\"\"\n    super().__init__(interval_seconds, pid, csv_path, csv_minutes)\n    self.fps_counter = FPSCounter()\n    self.target_fps = target_fps\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSProfiler.get_current_info","title":"<code>get_current_info()</code>","text":"<p>Get the current resource usage and FPS.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the current timestamp, CPU usage percentage, RAM usage in MiB, and FPS.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def get_current_info(self):\n    \"\"\"\n    Get the current resource usage and FPS.\n\n    Returns:\n        tuple: A tuple containing the current timestamp, CPU usage percentage, RAM usage in MiB, and FPS.\n    \"\"\"\n    current_time, cpu_percent, ram_mib = super().get_current_info()\n    self.fps_counter.update()\n    fps = int(self.fps_counter.get_fps())\n    return current_time, cpu_percent, ram_mib, fps\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSProfiler.update","title":"<code>update()</code>","text":"<p>Update the resource usage and FPS information, printing and saving to CSV if applicable.</p> <p>If the interval has elapsed, the current CPU, RAM, and FPS usage will be printed. If a CSV path is specified, the data will be written to the CSV file. If a target FPS is defined, attempts to maintain the target FPS.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing CPU usage percentage, RAM usage in MiB, and FPS.</p> Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def update(self):\n    \"\"\"\n    Update the resource usage and FPS information, printing and saving to CSV if applicable.\n\n    If the interval has elapsed, the current CPU, RAM, and FPS usage will be printed.\n    If a CSV path is specified, the data will be written to the CSV file.\n    If a target FPS is defined, attempts to maintain the target FPS.\n\n    Returns:\n        tuple: A tuple containing CPU usage percentage, RAM usage in MiB, and FPS.\n    \"\"\"\n    current_time, cpu_percent, ram_mib, fps = self.get_current_info()\n    if current_time - self.last_update_time &gt;= self.interval_seconds:\n        print(\n            f\"PID: {self.pid} - CPU Usage: {cpu_percent}% - total RAM: {ram_mib:.2f} MiB - FPS: {fps}\"\n        )\n        self.last_update_time = current_time\n    if self.csv_path:\n        self.update_csv(current_time, cpu_percent, ram_mib, fps)\n    if self.target_fps:\n        self.fps_counter.keep_target_fps(self.target_fps)\n    return cpu_percent, ram_mib, fps\n</code></pre>"},{"location":"lab/profiler/#kano.lab.profiler.FPSProfiler.update_csv","title":"<code>update_csv(current_time, cpu_percent, ram_mib, fps)</code>","text":"<p>Update the CSV file with the current resource usage and FPS.</p> <p>Parameters:</p> Name Type Description Default <code>current_time</code> <code>float</code> <p>The current timestamp.</p> required <code>cpu_percent</code> <code>float</code> <p>The current CPU usage as a percentage.</p> required <code>ram_mib</code> <code>float</code> <p>The current RAM usage in MiB.</p> required <code>fps</code> <code>int</code> <p>The current frames per second.</p> required Source code in <code>kano\\lab\\profiler.py</code> <pre><code>def update_csv(self, current_time, cpu_percent, ram_mib, fps):\n    \"\"\"\n    Update the CSV file with the current resource usage and FPS.\n\n    Args:\n        current_time (float): The current timestamp.\n        cpu_percent (float): The current CPU usage as a percentage.\n        ram_mib (float): The current RAM usage in MiB.\n        fps (int): The current frames per second.\n    \"\"\"\n    if os.path.isfile(self.csv_path):\n        df = pd.read_csv(self.csv_path)\n        df = df[df[\"time\"] &gt; current_time - self.csv_minutes * 60]\n    else:\n        df = pd.DataFrame(\n            columns=[\"time\", \"cpu_percent\", \"ram_mib\", \"fps\"]\n        )\n    new_line = {\n        \"time\": current_time,\n        \"cpu_percent\": cpu_percent,\n        \"ram_mib\": ram_mib,\n        \"fps\": fps,\n    }\n    df.loc[len(df)] = new_line\n    df.to_csv(self.csv_path, index=False, header=True)\n</code></pre>"},{"location":"lab/source_reader/","title":"Source reader classes","text":"<p>The <code>VideoStreamer</code> class streams video from a source (file or camera) and retrieves frames in real-time, ensuring that the current frame is always processed without delay. Unlike <code>cv2.VideoCapture</code>, which might introduce a delay while waiting for the next frame in the stream, <code>VideoStreamer</code> fetches the frame at the current time, making it ideal for real-time processing.</p>"},{"location":"lab/source_reader/#kano.lab.source_reader.VideoStreamer","title":"<code>kano.lab.source_reader.VideoStreamer</code>","text":"<p>A class to stream video from a source (file or camera), continuously read frames, and store them in a queue.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to the video source or camera index.</p> required <code>reconnect</code> <code>bool</code> <p>Whether to reconnect to the video source if the connection is lost. Default is True.</p> <code>True</code> Source code in <code>kano\\lab\\source_reader.py</code> <pre><code>class VideoStreamer:\n    \"\"\"\n    A class to stream video from a source (file or camera), continuously read frames, and store them in a queue.\n\n    Args:\n        source (str): Path to the video source or camera index.\n        reconnect (bool): Whether to reconnect to the video source if the connection is lost. Default is True.\n    \"\"\"\n\n    def __init__(\n        self, source: str, reconnect: bool = True, reconnect_time: float = 2\n    ):\n        \"\"\"\n        Initializes the VideoStreamer class to stream video from the specified source.\n\n        Args:\n            source (str): The path to the video source or camera index.\n            reconnect (bool): Whether to reconnect to the video source if the connection is lost.\n            reconnect_time (float): Time to play the source after out of frames or connection lost\n        \"\"\"\n        self.source = source\n        self.frame_queue = Queue(maxsize=5)\n        thread = threading.Thread(target=self._read_frames)\n        thread.start()\n        thread.daemon = True\n        self.stop = False\n        self.reconnect = reconnect\n        self.reconnect_time = reconnect_time\n\n    def _read_frames(self):\n        \"\"\"\n        Continuously reads frames from the video source and stores them in a queue.\n\n        If the video source is lost, it attempts to reconnect if `self.reconnect` is True.\n        \"\"\"\n        cap = cv2.VideoCapture(self.source)\n\n        if not cap.isOpened():\n            raise ValueError(f\"Error when playing {self.source}.\")\n\n        source_fps = cap.get(cv2.CAP_PROP_FPS)\n        running = True\n        fps_counter = FPSCounter()\n\n        while running:\n            ret, frame = cap.read()\n\n            if not ret or not self.stop:\n                if self.reconnect:\n                    print(\"Reconnect...\")\n                    time.sleep(self.reconnect_time)\n                    cap = cv2.VideoCapture(self.source)\n                    fps_counter = FPSCounter()\n                    continue\n                break\n\n            fps_counter.update()\n            fps_counter.keep_target_fps(source_fps)\n\n            try:\n                self.frame_queue.put_nowait(frame)\n            except:\n                pass\n\n        cap.release()\n\n    def get_latest_frame(self):\n        \"\"\"\n        Retrieves the latest frame from the queue.\n\n        Returns:\n            frame (ndarray): The most recent frame from the video source.\n        \"\"\"\n        return self.frame_queue.get()\n\n    def stop_stream(self):\n        \"\"\"\n        Stop the stream thread\n        \"\"\"\n        self.stop = True\n</code></pre>"},{"location":"lab/source_reader/#kano.lab.source_reader.VideoStreamer.__init__","title":"<code>__init__(source, reconnect=True, reconnect_time=2)</code>","text":"<p>Initializes the VideoStreamer class to stream video from the specified source.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the video source or camera index.</p> required <code>reconnect</code> <code>bool</code> <p>Whether to reconnect to the video source if the connection is lost.</p> <code>True</code> <code>reconnect_time</code> <code>float</code> <p>Time to play the source after out of frames or connection lost</p> <code>2</code> Source code in <code>kano\\lab\\source_reader.py</code> <pre><code>def __init__(\n    self, source: str, reconnect: bool = True, reconnect_time: float = 2\n):\n    \"\"\"\n    Initializes the VideoStreamer class to stream video from the specified source.\n\n    Args:\n        source (str): The path to the video source or camera index.\n        reconnect (bool): Whether to reconnect to the video source if the connection is lost.\n        reconnect_time (float): Time to play the source after out of frames or connection lost\n    \"\"\"\n    self.source = source\n    self.frame_queue = Queue(maxsize=5)\n    thread = threading.Thread(target=self._read_frames)\n    thread.start()\n    thread.daemon = True\n    self.stop = False\n    self.reconnect = reconnect\n    self.reconnect_time = reconnect_time\n</code></pre>"},{"location":"lab/source_reader/#kano.lab.source_reader.VideoStreamer.get_latest_frame","title":"<code>get_latest_frame()</code>","text":"<p>Retrieves the latest frame from the queue.</p> <p>Returns:</p> Name Type Description <code>frame</code> <code>ndarray</code> <p>The most recent frame from the video source.</p> Source code in <code>kano\\lab\\source_reader.py</code> <pre><code>def get_latest_frame(self):\n    \"\"\"\n    Retrieves the latest frame from the queue.\n\n    Returns:\n        frame (ndarray): The most recent frame from the video source.\n    \"\"\"\n    return self.frame_queue.get()\n</code></pre>"},{"location":"lab/source_reader/#kano.lab.source_reader.VideoStreamer.stop_stream","title":"<code>stop_stream()</code>","text":"<p>Stop the stream thread</p> Source code in <code>kano\\lab\\source_reader.py</code> <pre><code>def stop_stream(self):\n    \"\"\"\n    Stop the stream thread\n    \"\"\"\n    self.stop = True\n</code></pre>"}]}